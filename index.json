[
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/1-introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "Learn how to build a Semantic Video Search Vector Database using AWS services such as SageMaker, S3, OpenSearch, ECS Fargate, and Lambda.",
	"content": "Welcome to the \u0026ldquo;Semantic Video Search Vector Database\u0026rdquo; workshop! In this workshop, we will guide you through building a comprehensive video search system using AWS services. You will learn how to ingest, process, and search video data efficiently using AWS tools.\nModules 1. Create OpenSearch Domain and Index with Dataset given Setting Up S3 for Video Storage\nObjective: Learn how to use Amazon S3 to store and manage video data. Description: Discover how to set up and configure S3 buckets for video storage, manage data efficiently, and ensure accessibility for processing. Ingesting Data with ECS Fargate\nObjective: Understand how to use ECS Fargate for data ingestion and processing. Description: Learn how to deploy and manage containerized applications using ECS Fargate to handle video data ingestion and preprocessing. Feature Extraction Using SageMaker and ECS\nObjective: Extract meaningful features from video data using SageMaker. Description: Implement feature extraction algorithms to convert video data into searchable vectors. Learn how to leverage SageMaker’s tools for processing and analyzing video content. Implementing OpenSearch for Vector Database\nObjective: Set up and use OpenSearch for storing and querying video vectors. Description: Configure OpenSearch as a vector database to enable fast and efficient search functionality. Learn how to index and retrieve video features for semantic search. 2. Deploy with Terraform Deploying the Semantic Video Search System Objective: Deploy the complete video search system using Terraform. Description: Use Terraform to automate the deployment of AWS resources, including SageMaker, S3, ECS Fargate, OpenSearch, and Lambda functions. Learn how to set up the entire video search system with ease. Overview 1. Amazon SageMaker: Amazon SageMaker is a fully managed service that provides tools for building, training, and deploying machine learning models. It offers integrated Jupyter notebooks, automated model tuning, and built-in algorithms, making it easier to develop and manage machine learning workflows.\n2. Amazon Simple Storage Service (S3): Amazon S3 is a scalable object storage service that provides high availability and durability for your data. It is commonly used for storing large amounts of data, including video files, with a pay-as-you-go pricing model.\n3. Amazon Elastic Container Service (ECS) Fargate: ECS Fargate allows you to run containers without managing the underlying infrastructure. Fargate automates the provisioning and scaling of containerized applications, simplifying data ingestion and processing tasks.\n4. OpenSearch: OpenSearch is a search and analytics engine that helps you store, search, and analyze large volumes of data quickly. It provides powerful search capabilities and is ideal for implementing vector databases for semantic search.\n5. AWS Lambda: AWS Lambda is a serverless compute service that lets you run code in response to events without provisioning or managing servers. Lambda functions can be used to automate workflows, process data, and integrate various AWS services.\nConclusion By completing this workshop, you will gain hands-on experience with AWS services to build a scalable and efficient Semantic Video Search Vector Database. You will be equipped with the skills to manage video data, extract features, and implement a powerful search system using AWS technologies.\nJoin us and start building your own video search solution today!\nKeywords: AWS SageMaker, Amazon S3, Amazon ECS Fargate, OpenSearch, AWS Lambda\n"
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/",
	"title": "Semantic Video Search Vector Database",
	"tags": [],
	"description": "Learn how to build a Semantic Video Search Vector Database using AWS services such as SageMaker, S3, OpenSearch, ECS Fargate, and Lambda.",
	"content": "Semantic Video Search Vector Database Workshop Overview Welcome to the \u0026ldquo;Semantic Video Search Vector Database\u0026rdquo; workshop! In this workshop, you\u0026rsquo;ll learn how to build a comprehensive video search system using AWS services such as SageMaker, S3, OpenSearch, ECS Fargate, and Lambda. We will guide you through each step of ingesting data, extracting features, and deploying a vector database for semantic search. You\u0026rsquo;ll have the opportunity to apply your knowledge through hands-on exercises, enhancing your skills and understanding of how to integrate AWS technologies to create an efficient and scalable video search solution.\nContents Introduction Setting Up S3 for Video Storage Ingesting Data with ECS Fargate 3.1 Create VPC 3.2 Set Up ECR Repository 3.3 Create ECS Task Definition 3.4 Run ECS Task Feature Extraction Using SageMaker and ECS 4.1 Extract Keyframes Using ECS 4.2 Embedding Processing with SageMaker Implementing OpenSearch for Vector Database 5.1 Set Up OpenSearch Cluster 5.2 Create Index and Indexing Data With Python SDK 5.3 Query by Text Deploy with Terraform 6.1 Setup 6.2 Processing Data 6.3 Embedding 6.4 VectorDB 6.5 CMS "
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/2-settup-s3/",
	"title": "Setting Up S3 for Video Storage",
	"tags": [],
	"description": "Modules",
	"content": "1.1 Create an S3 Bucket Navigate to S3 by clicking on the Services menu, under the Storage section. Click on Create bucket button. In the General Configuration. Bucket name: Enter ai-challenge-2024 Note: S3 Bucket names are globally unique, choose a name that is available. Region: Select US East (N. Virginia) us-east-1 (i.e same region as the Kinesis data stream). In the Default encryption. Encryption key type: Leave the key type as Amazon S3 key (SSE-S3). Bucket key: Select Enable Click on Create bucket button 1.2 Create Folders in S3 Bucket Click on the bucket name ai-challenge-2024. Click on Create folder button. Enter the folder name as keyframes and click on Save. Repeat the above steps to create another folder with the name video. "
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/3-ingrest-data/3.1-create-vpc/",
	"title": "Create VPC",
	"tags": [],
	"description": "Modules",
	"content": "Create a VPC Navigate to VPC by clicking on the Services menu, under the Networking \u0026amp; Content Delivery section. Click on Your VPCs in the left navigation pane. Click on Create VPC button. In the VPC settings page. Resources to create : Select VPC and more Name tag: Enter ai-challenge-vpc IPv4 CIDR block: Enter 10.0.0.0/16 Click on Create VPC button. With the VPC and more option, you will receive a complete template that includes subnet, route table, and VPCE (S3 gateway endpoint), facilitating the execution of ECS tasks and SageMaker jobs.\n"
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/3-ingrest-data/",
	"title": "Ingesting Data with ECS Fargate",
	"tags": [],
	"description": "Modules",
	"content": "Overview In this module, you will learn how to ingest data into your video search system using ECS Fargate. We will guide you through the process of creating a task definition, configuring network settings, and running the task to ingest data from S3 into your ECS Fargate cluster.\nContents Create VPC Set Up ECR Repository Create ECS Task Definition Run ECS Task "
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/3-ingrest-data/3.2-erc-repo/",
	"title": "Set Up ECR Repository",
	"tags": [],
	"description": "Modules",
	"content": "Create ECR Image 1 Create an ECR Repository Navigate to ECR by clicking on the Services menu, under the Container section. Click on Create repository button. In the General settings. Repository name: Enter ai-challenge-2024 Image tag mutability: Select Mutable In the Encryption settings: Select AES256 Click on Create repository button 2 Create Docker Image Create a new directory called ecr-image and navigate to it. |-- Makefile |-- cmd | `-- task-load-to-s3 | |-- Dockerfile | |-- main.go | `-- processor.go |-- go.mod |-- go.sum Create file main.go in the cmd/task-load-to-s3 directory. package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;github.com/aws/aws-sdk-go/aws\u0026#34; \u0026#34;github.com/aws/aws-sdk-go/aws/session\u0026#34; ) const ( zippath = \u0026#34;/tmp/yourfile.zip\u0026#34; unzippath = \u0026#34;/tmp/unzipped\u0026#34; ) func main() { zipURL := os.Getenv(\u0026#34;URL_TO_DOWNLOAD\u0026#34;) bucket := os.Getenv(\u0026#34;S3_BUCKET_NAME\u0026#34;) folder := os.Getenv(\u0026#34;S3_FOLDER_NAME\u0026#34;) if zipURL == \u0026#34;\u0026#34; || bucket == \u0026#34;\u0026#34; || folder == \u0026#34;\u0026#34; { log.Fatal(\u0026#34;URL_TO_DOWNLOAD and S3_BUCKET_NAME must be set\u0026#34;) } if folder!=\u0026#34;video\u0026#34; \u0026amp;\u0026amp; folder!=\u0026#34;keyframes\u0026#34; { log.Fatal(\u0026#34;S3_FOLDER_NAME must be either \u0026#39;videos\u0026#39; or \u0026#39;images\u0026#39;\u0026#34;) } // Set up AWS session sess, err := session.NewSession(\u0026amp;aws.Config{ Region: aws.String(\u0026#34;ap-southeast-1\u0026#34;), }) if err != nil { log.Fatalf(\u0026#34;Failed to create AWS session: %v\u0026#34;, err) } processor := NewProcessor(sess, bucket, folder) fmt.Println(\u0026#34;Downloading file from\u0026#34;, zipURL) // Download the zip file err = processor.DownloadZip(zipURL) if err != nil { log.Fatalf(\u0026#34;Failed to download file: %v\u0026#34;, err) } // Unzip the file err = processor.unzip() if err != nil { log.Fatalf(\u0026#34;Failed to unzip file: %v\u0026#34;, err) } fmt.Println(\u0026#34;Uploading file to S3 bucket\u0026#34;, bucket) // Upload unzipped content to S3 err = processor.uploadToS3() if err != nil { log.Fatalf(\u0026#34;Failed to upload to S3: %v\u0026#34;, err) } fmt.Println(\u0026#34;File uploaded successfully\u0026#34;) } Create file processor.go in the cmd/task-load-to-s3 directory. package main import ( \u0026#34;archive/zip\u0026#34; \u0026#34;io\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os\u0026#34; \u0026#34;path/filepath\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;github.com/aws/aws-sdk-go/aws\u0026#34; \u0026#34;github.com/aws/aws-sdk-go/aws/session\u0026#34; \u0026#34;github.com/aws/aws-sdk-go/service/s3\u0026#34; ) type Proccessor struct { sess *session.Session bucket string folder string } func NewProcessor(sess *session.Session, bucket string, folder string) *Proccessor { return \u0026amp;Proccessor{ sess: sess, bucket: bucket, folder: folder, } } func (p *Proccessor) unzip() error { r, err := zip.OpenReader(zippath) if err != nil { return err } defer r.Close() for _, f := range r.File { rc, err := f.Open() if err != nil { return err } defer rc.Close() fpath := filepath.Join(unzippath, f.Name) if f.FileInfo().IsDir() { os.MkdirAll(fpath, os.ModePerm) } else { os.MkdirAll(filepath.Dir(fpath), os.ModePerm) outFile, err := os.Create(fpath) if err != nil { return err } defer outFile.Close() _, err = io.Copy(outFile, rc) if err != nil { return err } } } return nil } func (p *Proccessor) uploadToS3() error { svc := s3.New(p.sess) err := filepath.Walk(unzippath, func(path string, info os.FileInfo, err error) error { if err != nil { return err } if info.IsDir() { return nil } file, err := os.Open(path) if err != nil { return err } defer file.Close() key := filepath.ToSlash(path) key = key[strings.Index(key, p.folder):] key = strings.Replace(key, p.folder, \u0026#34;\u0026#34;, 1) fullKey := filepath.Join(p.folder, key) fullKey = strings.Replace(fullKey, \u0026#34;\\\\\u0026#34;, \u0026#34;/\u0026#34;, -1) _, err = svc.PutObject(\u0026amp;s3.PutObjectInput{ Bucket: aws.String(p.bucket), Key: aws.String(fullKey), Body: file, }) if err != nil { return err } return nil }) return err } func (p *Proccessor) DownloadZip(url string) error { resp, err := http.Get(url) if err != nil { return err } defer resp.Body.Close() out, err := os.Create(zippath) if err != nil { return err } defer out.Close() _, err = io.Copy(out, resp.Body) return err } Create a Dockerfile in the cmd/task-load-to-s3 directory. FROM golang:1.20-alpine3.18 AS builder WORKDIR /app COPY . . RUN go build -o main ./cmd/task-load-to-s3/*.go FROM alpine:3.18 WORKDIR /app COPY --from=builder /app/main . ENTRYPOINT [\u0026#34;/app/main\u0026#34;] Create a Makefile in the root directory. run: go run ./cmd/task-load-to-s3/*.go build: docker build -f ./cmd/task-load-to-s3/Dockerfile -t keyframes:v1 . push: docker tag keyframes:v1 \u0026lt;aws account_id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/ai-challenge-2024:keyframes docker push \u0026lt;aws account_id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/ai-challenge-2024:keyframes Install the required dependencies. go mod init keyframes go mod tidy Run the following command to build the docker image. make build Push the docker image to ECR. Go to the ECR console. Click on the repository ai-challenge-2024. Click on the View push commands button. Run the commands to login to ECR. aws ecr get-login-password --region ap-southeast-1 | docker login --username AWS --password-stdin \u0026lt;aws account_id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com Push the docker image to ECR. make push "
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/3-ingrest-data/3.3-ecs-task/",
	"title": "Create ECS Task Definition",
	"tags": [],
	"description": "Modules",
	"content": "1 Create an ECS Cluster Navigate to ECS by clicking on the Services menu, under the Compute section. Click on Create Cluster button. In the Cluster configuration Cluster name: Enter ai-challenge-ecs-cluster In the Infrastructure Provisioning model: Select AWS Fargate (serverless) Click on Create button Wait for 2 minutes for the ECS cluster to be created.\n2 Create an ECS Task Role 2.1 Create an IAM Role Navigate to IAM by clicking on the Services menu, under the Security, Identity, \u0026amp; Compliance section. Click on Roles in the left navigation pane. Click on Create role button. In the Select type of trusted entity Select AWS service Choose the service that will use this role: ECS Click on Next: Permissions button Choose Next to Review page. In the Review page. Role name: Enter TaskRole Click on Create role button 2.2 Attach Policies to the Role Click on the TaskRole role. Click on Add Permission button. Click on Create Inline Policy button. Choose JSON tab. Paste this json in the Policy Document editor. { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::ai-challenge-2024/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:*:*:*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ecr:GetAuthorizationToken\u0026#34;, \u0026#34;ecr:BatchCheckLayerAvailability\u0026#34;, \u0026#34;ecr:GetDownloadUrlForLayer\u0026#34;, \u0026#34;ecr:BatchGetImage\u0026#34;, \u0026#34;logs:CreateLogGroup\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } 3 Create an ECS Task Definition Nhấp vào Task Definitions trong thanh điều hướng bên trái. Nhấp vào nút Create new Task Definition. Chọn Create new task with JSON. Dán đoạn JSON sau vào trình chỉnh sửa Task Definition: { { \u0026#34;containerDefinitions\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;keyframes-container\u0026#34;, \u0026#34;image\u0026#34;: \u0026#34;\u0026lt;aws account id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/ai-challenge-2024:keyframes\u0026#34;, \u0026#34;cpu\u0026#34;: 2048, \u0026#34;memory\u0026#34;: 6144, \u0026#34;portMappings\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;80\u0026#34;, \u0026#34;containerPort\u0026#34;: 80, \u0026#34;hostPort\u0026#34;: 80, \u0026#34;protocol\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;appProtocol\u0026#34;: \u0026#34;http\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;433\u0026#34;, \u0026#34;containerPort\u0026#34;: 433, \u0026#34;hostPort\u0026#34;: 433, \u0026#34;protocol\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;appProtocol\u0026#34;: \u0026#34;http\u0026#34; } ], \u0026#34;essential\u0026#34;: true, \u0026#34;environment\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;S3_BUCKET_NAME\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;ai-challenge-2024\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;S3_FOLDER_NAME\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;keyframes\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;URL_TO_DOWNLOAD\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;\u0026#34; } ], \u0026#34;mountPoints\u0026#34;: [], \u0026#34;volumesFrom\u0026#34;: [], \u0026#34;logConfiguration\u0026#34;: { \u0026#34;logDriver\u0026#34;: \u0026#34;awslogs\u0026#34;, \u0026#34;options\u0026#34;: { \u0026#34;awslogs-group\u0026#34;: \u0026#34;/ecs/keyframes-task\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;non-blocking\u0026#34;, \u0026#34;awslogs-create-group\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;max-buffer-size\u0026#34;: \u0026#34;25m\u0026#34;, \u0026#34;awslogs-region\u0026#34;: \u0026#34;ap-southeast-1\u0026#34;, \u0026#34;awslogs-stream-prefix\u0026#34;: \u0026#34;ecs\u0026#34; } }, \u0026#34;systemControls\u0026#34;: [] } ], \u0026#34;family\u0026#34;: \u0026#34;keyframes-task\u0026#34;, \u0026#34;taskRoleArn\u0026#34;: \u0026#34;arn:aws:iam::\u0026lt;aws account id\u0026gt;:role/TaskRole\u0026#34;, \u0026#34;executionRoleArn\u0026#34;: \u0026#34;arn:aws:iam::\u0026lt;aws account id\u0026gt;:role/TaskRole\u0026#34;, \u0026#34;networkMode\u0026#34;: \u0026#34;awsvpc\u0026#34;, \u0026#34;placementConstraints\u0026#34;: [], \u0026#34;requiresCompatibilities\u0026#34;: [ \u0026#34;FARGATE\u0026#34; ], \u0026#34;cpu\u0026#34;: \u0026#34;2048\u0026#34;, \u0026#34;memory\u0026#34;: \u0026#34;6144\u0026#34;, \u0026#34;ephemeralStorage\u0026#34;: { \u0026#34;sizeInGiB\u0026#34;: 21 }, \u0026#34;runtimePlatform\u0026#34;: { \u0026#34;cpuArchitecture\u0026#34;: \u0026#34;X86_64\u0026#34;, \u0026#34;operatingSystemFamily\u0026#34;: \u0026#34;LINUX\u0026#34; }, \u0026#34;tags\u0026#34;: [] } } Cấu Hình Chính Xác Cách Container Chạy Trong Tác Vụ Định Nghĩa Container\nname: keyframes-container – Tên của container.\nimage: \u0026lt;aws account id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/ai-challenge-2024:keyframes – Docker image được lưu trữ trong Amazon ECR mà container sẽ sử dụng.\ncpu: 2048 – Phân bổ 2 vCPUs cho container.\nmemory: 6144 – Phân bổ 6 GB bộ nhớ cho container.\nportMappings:\ncontainerPort: 80 – Mở cổng 80 cho lưu lượng HTTP. containerPort: 433 – Mở cổng 433 cho lưu lượng (lưu ý: có thể cần chỉnh sửa thành 443 cho HTTPS). essential: true – Chỉ ra rằng container là quan trọng đối với tác vụ; nếu container này dừng lại, toàn bộ tác vụ sẽ dừng lại.\nBiến Môi Trường Biến môi trường được truyền vào container để cấu hình hành vi:\nS3_BUCKET_NAME: \u0026quot;ai-challenge-2024\u0026quot; – Xác định bucket S3 dùng để lưu trữ keyframes. S3_FOLDER_NAME: \u0026quot;keyframes\u0026quot; – Xác định thư mục trong bucket S3 nơi lưu trữ keyframes. URL_TO_DOWNLOAD: \u0026quot;\u0026quot; – Một placeholder cho URL mà container sẽ sử dụng để tải xuống. Cấu Hình Logging Thiết lập logging tới AWS CloudWatch Logs để theo dõi và gỡ lỗi:\nlogDriver: awslogs – Sử dụng driver AWS Logs để gửi logs tới CloudWatch. awslogs-group: /ecs/keyframes-task – Xác định nhóm CloudWatch Logs nơi lưu trữ logs. awslogs-create-group: true – Tự động tạo nhóm log nếu nó chưa tồn tại. max-buffer-size: 25m – Xác định kích thước bộ đệm tối đa cho logs. awslogs-region: ap-southeast-1 – Đặt khu vực AWS cho logging. awslogs-stream-prefix: ecs – Thêm một tiền tố vào các luồng log để giúp nhận diện chúng dễ dàng. Cài Đặt Tác Vụ\nfamily: \u0026quot;keyframes-task\u0026quot; – Tên gia đình của tác vụ, được sử dụng để xác định nó trong ECS. taskRoleArn: arn:aws:iam::\u0026lt;aws account id\u0026gt;:role/TaskRole – Xác định vai trò IAM mà tác vụ sử dụng để có quyền truy cập các dịch vụ AWS. executionRoleArn: arn:aws:iam::\u0026lt;aws account id\u0026gt;:role/TaskRole – Xác định vai trò IAM được sử dụng bởi tác nhân ECS để kéo images và xuất bản logs. Cấu Hình Mạng\nnetworkMode: awsvpc – Sử dụng chế độ mạng AWS VPC, cho phép tác vụ có các giao diện mạng, nhóm bảo mật và giao diện mạng đàn hồi riêng. requiresCompatibilities: [\u0026quot;FARGATE\u0026quot;] – Xác định rằng tác vụ yêu cầu loại khởi chạy Fargate. Cấu Hình Tài Nguyên\ncpu: \u0026quot;2048\u0026quot; – Phân bổ 2 vCPUs cho tác vụ. memory: \u0026quot;6144\u0026quot; – Phân bổ 6 GB bộ nhớ cho tác vụ. ephemeralStorage: sizeInGiB: 21 – Cung cấp 21 GB lưu trữ tạm thời cho dữ liệu tạm thời do tác vụ tạo ra. Cấu Hình Nền Tảng\nruntimePlatform: cpuArchitecture: X86_64 – Xác định kiến trúc CPU. operatingSystemFamily: LINUX – Xác định hệ điều hành được sử dụng. Định nghĩa tác vụ này đảm bảo một môi trường linh hoạt, mở rộng và an toàn để xử lý keyframes trong AWS ECS sử dụng loại khởi chạy Fargate, cho phép bạn chạy các container một cách hiệu quả mà không cần quản lý máy chủ.\n"
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/3-ingrest-data/3.4-run-task/",
	"title": "Run ECS Task",
	"tags": [],
	"description": "Modules",
	"content": "1 Prepare Script to Run Task import os import boto3 s3_client = boto3.client(\u0026#34;s3\u0026#34;) ecs_client = boto3.client(\u0026#34;ecs\u0026#34;) def lambda_handler(): cluster_name = os.environ[\u0026#34;ECS_CLUSTER_NAME\u0026#34;] task_definition = os.environ[\u0026#34;TASK_DEFINITION\u0026#34;] subnet_id = os.environ[\u0026#34;SUBNET_ID\u0026#34;] security_group_id = os.environ[\u0026#34;SECURITY_GROUP_ID\u0026#34;] # # Cấu hình network cho ECS task network_config = { \u0026#34;awsvpcConfiguration\u0026#34;: { \u0026#34;subnets\u0026#34;: [subnet_id], \u0026#34;securityGroups\u0026#34;: [security_group_id], \u0026#34;assignPublicIp\u0026#34;: \u0026#34;ENABLED\u0026#34;, } } keyframes_urls = [ \u0026#34;https://atm249495-s3user.vcos.cloudstorage.com.vn/aic24-b5/Keyframes_L01.zip\u0026#34;, \u0026#34;https://atm249497-s3user.vcos.cloudstorage.com.vn/aic24-b7/Keyframes_L03.zip\u0026#34;, \u0026#34;https://atm249498-s3user.vcos.cloudstorage.com.vn/aic24-b8/Keyframes_L04.zip\u0026#34;, \u0026#34;https://atm249495-s3user.vcos.cloudstorage.com.vn/aic24-b5/Keyframes_L05.zip\u0026#34;, \u0026#34;https://atm249496-s3user.vcos.cloudstorage.com.vn/aic24-b6/Keyframes_L06.zip\u0026#34;, \u0026#34;https://atm249497-s3user.vcos.cloudstorage.com.vn/aic24-b7/Keyframes_L07.zip\u0026#34;, \u0026#34;https://atm249498-s3user.vcos.cloudstorage.com.vn/aic24-b8/Keyframes_L08.zip\u0026#34;, \u0026#34;https://atm249495-s3user.vcos.cloudstorage.com.vn/aic24-b5/Keyframes_L09.zip\u0026#34;, \u0026#34;https://atm249496-s3user.vcos.cloudstorage.com.vn/aic24-b6/Keyframes_L10.zip\u0026#34;, \u0026#34;https://atm249497-s3user.vcos.cloudstorage.com.vn/aic24-b7/Keyframes_L11.zip\u0026#34;, \u0026#34;https://atm249498-s3user.vcos.cloudstorage.com.vn/aic24-b8/Keyframes_L12.zip\u0026#34;, ] video_urls = [ \u0026#34;https://atm249495-s3user.vcos.cloudstorage.com.vn/aic24-b5/Videos_L01.zip\u0026#34;, \u0026#34;https://atm249496-s3user.vcos.cloudstorage.com.vn/aic24-b6/Videos_L02.zip\u0026#34;, \u0026#34;https://atm249497-s3user.vcos.cloudstorage.com.vn/aic24-b7/Videos_L03.zip\u0026#34;, \u0026#34;https://atm249498-s3user.vcos.cloudstorage.com.vn/aic24-b8/Videos_L04.zip\u0026#34;, \u0026#34;https://atm249495-s3user.vcos.cloudstorage.com.vn/aic24-b5/Videos_L05.zip\u0026#34;, \u0026#34;https://atm249496-s3user.vcos.cloudstorage.com.vn/aic24-b6/Videos_L06.zip\u0026#34;, \u0026#34;https://atm249497-s3user.vcos.cloudstorage.com.vn/aic24-b7/Videos_L07.zip\u0026#34;, \u0026#34;https://atm249498-s3user.vcos.cloudstorage.com.vn/aic24-b8/Videos_L08.zip\u0026#34;, \u0026#34;https://atm249495-s3user.vcos.cloudstorage.com.vn/aic24-b5/Videos_L09.zip\u0026#34;, \u0026#34;https://atm249496-s3user.vcos.cloudstorage.com.vn/aic24-b6/Videos_L10.zip\u0026#34;, \u0026#34;https://atm249497-s3user.vcos.cloudstorage.com.vn/aic24-b7/Videos_L11.zip\u0026#34;, \u0026#34;https://atm249498-s3user.vcos.cloudstorage.com.vn/aic24-b8/Videos_L12.zip\u0026#34;, ] for zip_file_url in keyframes_urls: run_task_input = { \u0026#34;cluster\u0026#34;: cluster_name, \u0026#34;launchType\u0026#34;: \u0026#34;FARGATE\u0026#34;, \u0026#34;taskDefinition\u0026#34;: task_definition, \u0026#34;networkConfiguration\u0026#34;: network_config, \u0026#34;overrides\u0026#34;: { \u0026#34;containerOverrides\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;keyframes-container\u0026#34;, \u0026#34;environment\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;URL_TO_DOWNLOAD\u0026#34;, \u0026#34;value\u0026#34;: zip_file_url, }, { \u0026#34;name\u0026#34;: \u0026#34;S3_BUCKET_NAME\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;ai-challenge-2024\u0026#34;, }, { \u0026#34;name\u0026#34;: \u0026#34;S3_FOLDER_NAME\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;keyframes\u0026#34;, }, ], } ] }, } response = ecs_client.run_task(**run_task_input) for zip_file_url in video_urls: run_task_input = { \u0026#34;cluster\u0026#34;: cluster_name, \u0026#34;launchType\u0026#34;: \u0026#34;FARGATE\u0026#34;, \u0026#34;taskDefinition\u0026#34;: task_definition, \u0026#34;networkConfiguration\u0026#34;: network_config, \u0026#34;overrides\u0026#34;: { \u0026#34;containerOverrides\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;keyframes-container\u0026#34;, \u0026#34;environment\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;URL_TO_DOWNLOAD\u0026#34;, \u0026#34;value\u0026#34;: zip_file_url, }, { \u0026#34;name\u0026#34;: \u0026#34;S3_BUCKET_NAME\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;ai-challenge-2024\u0026#34;, }, { \u0026#34;name\u0026#34;: \u0026#34;S3_FOLDER_NAME\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;video\u0026#34;, }, ], } ] }, } response = ecs_client.run_task(**run_task_input) return { \u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: f\u0026#39;Task created successfully with Task ARN: {response[\u0026#34;tasks\u0026#34;][0][\u0026#34;taskArn\u0026#34;]}\u0026#39;, } if __name__ == \u0026#34;__main__\u0026#34;: lambda_handler() Environment Variables\nBelow are the key environment variables required for setting up and running the ECS task:\nECS_CLUSTER_NAME: Specifies the name of the ECS cluster where the task will be deployed. TASK_DEFINITION: Defines the name of the ECS task definition used for the task. SUBNET_ID: The subnet ID where the ECS task will be launched, determining the network within the VPC. SECURITY_GROUP_ID: The security group ID that defines firewall rules and access permissions for the ECS task. CONTAINER_NAME: Identifies the name of the container in the ECS task definition. Example Configuration\nECS_CLUSTER_NAME: ai-challenge-2024\nTASK_DEFINITION: keyframes-task\nSUBNET_ID: subnet-0f9d3b7b1b7b7b7b7\nSECURITY_GROUP_ID: sg-0f9d3b7b1b7b7b7b7\nCONTAINER_NAME: keyframes-container\nEach of these variables plays a crucial role in the task setup, ensuring proper deployment and access control within your AWS environment.\n2 Run Task Run the script to ingest data to S3:\npython run_task.py The script will create tasks to download and ingest data to S3. 3 Monitor Task Navigate to CloudWatch by clicking on the Services menu, under the Management \u0026amp; Governance section. Click on Log groups in the left navigation pane. Click on the log group with the name /ecs/keyframes-task. Click on the log stream with the latest log stream name. You can monitor the logs of the task to check the status of the task.\n4 Check Data in S3 Navigate to S3 by clicking on the Services menu, under the Storage section. Click on the bucket name ai-challenge-2024. Check the folders keyframes and video to see the ingested data. Check the total size of the keyframes and video folders: Navigate to the keyframes folder. Click on the Actions dropdown. Click on Calculate total size. Repeat the above steps for the video folder. keyframes: 18.7 GB video: 55.6 GB "
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/4-process-data/",
	"title": "Feature Extraction Using SageMaker and ECS",
	"tags": [],
	"description": "Learn how to build a Semantic Video Search Vector Database using AWS services such as SageMaker, S3, OpenSearch, ECS Fargate, and Lambda.",
	"content": "Overview In this module, you will learn how to extract meaningful features from video data using Amazon SageMaker and ECS. We will guide you through the process of setting up SageMaker, creating a feature extraction pipeline, and deploying the pipeline on ECS Fargate to process video data efficiently.\nContents Extract Keyframes Using ECS\nEmbedding Processing with SageMaker\n"
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/4-process-data/4.1-extract-keyframes-ecs/",
	"title": "Extract Keyframes Using ECS",
	"tags": [],
	"description": "Learn how to build a Semantic Video Search Vector Database using AWS services such as SageMaker, S3, OpenSearch, ECS Fargate, and Lambda.",
	"content": "1 Create Docker Image for Keyframes Extraction Create a new directory called ecr-extract-keyframes and navigate to it. . |-- Dockerfile |-- get-object-s3.py |-- requirements.txt |-- run-task.py |-- split-video.py Create file Dockerfile in the directory. FROM python:3.9-slim RUN apt-get update \u0026amp;\u0026amp; \\ apt-get install -y \\ libgl1-mesa-glx \\ libglib2.0-0 \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* COPY requirements.txt . RUN pip install --no-cache-dir -r requirements.txt COPY . /app WORKDIR /app CMD [\u0026#34;python\u0026#34;, \u0026#34;extract-keyframes.py\u0026#34;] Create file extract-keyframes.py in the directory. import boto3 import cv2 import os import numpy as np import tempfile import csv from io import StringIO class S3KeyframeUpdater: def __init__(self, bucket_name, video_key, folder_prefix, output_csv_key): self.bucket_name = bucket_name self.video_key = video_key self.folder_prefix = folder_prefix self.output_csv_key = output_csv_key self.s3 = boto3.client(\u0026#39;s3\u0026#39;) def list_s3_objects(self, prefix): response = self.s3.list_objects_v2(Bucket=self.bucket_name, Prefix=prefix) if \u0026#39;Contents\u0026#39; in response: return [obj[\u0026#39;Key\u0026#39;] for obj in response[\u0026#39;Contents\u0026#39;]] return [] def get_s3_object(self, key): return self.s3.get_object(Bucket=self.bucket_name, Key=key)[\u0026#39;Body\u0026#39;].read() def update_keyframe_metadata(self): print(f\u0026#39;Download video from {self.video_key}\u0026#39;) video_data = self.get_s3_object(self.video_key) with tempfile.NamedTemporaryFile(delete=False, suffix=\u0026#39;.mp4\u0026#39;) as temp_video_file: temp_video_file.write(video_data) temp_video_path = temp_video_file.name video = cv2.VideoCapture(temp_video_path) keyframe_keys = self.list_s3_objects(self.folder_prefix) number_of_keyframes = len(keyframe_keys) count = 0 frame_number = 0 csv_buffer = StringIO() csv_writer = csv.writer(csv_buffer) csv_writer.writerow([\u0026#39;VideoName\u0026#39;, \u0026#39;KeyframeName\u0026#39;, \u0026#39;FrameNumber\u0026#39;]) while True: ret, frame = video.read() if not ret or count \u0026gt;= number_of_keyframes: break gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) keyframe_data = self.get_s3_object(keyframe_keys[count]) keyframe_img = cv2.imdecode(np.frombuffer(keyframe_data, np.uint8), cv2.IMREAD_GRAYSCALE) result = cv2.matchTemplate(gray_frame, keyframe_img, cv2.TM_CCOEFF_NORMED) _, max_val, _, _ = cv2.minMaxLoc(result) if max_val \u0026gt; 0.9: name = os.path.basename(keyframe_keys[count]) self.s3.copy_object( Bucket=self.bucket_name, CopySource={\u0026#39;Bucket\u0026#39;: self.bucket_name, \u0026#39;Key\u0026#39;: keyframe_keys[count]}, Key=keyframe_keys[count], MetadataDirective=\u0026#39;REPLACE\u0026#39;, Metadata={ \u0026#39;VideoKey\u0026#39;: self.video_key, \u0026#39;FrameNumber\u0026#39;: str(frame_number) } ) print(f\u0026#39;Updated metadata for {name} at frame {frame_number}\u0026#39;) csv_writer.writerow([os.path.basename(self.video_key), name, frame_number]) count += 1 frame_number += 1 video.release() os.remove(temp_video_path) csv_buffer.seek(0) self.s3.put_object( Bucket=self.bucket_name, Key=self.output_csv_key, Body=csv_buffer.getvalue(), ContentType=\u0026#39;text/csv\u0026#39; ) print(f\u0026#39;Result has saved to {self.output_csv_key} on S3\u0026#39;) if __name__ == \u0026#34;__main__\u0026#34;: bucket_name = os.environ[\u0026#39;BUCKET_NAME\u0026#39;] folder_prefix = os.environ[\u0026#39;FOLDER_PREFIX\u0026#39;] video_key = os.environ[\u0026#39;VIDEO_KEY\u0026#39;] output_csv_key = f\u0026#39;metadata/{video_key.split(\u0026#34;/\u0026#34;)[1].split(\u0026#34;.\u0026#34;)[0]}.csv\u0026#39; if not bucket_name or not folder_prefix or not video_key: raise ValueError(\u0026#39;Missing environment variables\u0026#39;) print(\u0026#34;Start updating keyframe metadata: \u0026#34;, bucket_name, video_key, folder_prefix, output_csv_key) updater = S3KeyframeUpdater(bucket_name, video_key, folder_prefix, output_csv_key) updater.update_keyframe_metadata() Create a requirements.txt in the directory. boto3 opencv-python-headless numpy Build the docker image. docker build -t ai-challenge-2024:keyframe-matcher . Tag the docker image. docker tag ai-challenge-2024:keyframe-matcher \u0026lt;aws account_id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/ai-challenge-2024:keyframe-matcher Push the docker image to ECR. Go to the ECR console. Click on the repository ai-challenge-2024. Click on the View push commands button. Run the commands to login to ECR. aws ecr get-login-password --region ap-southeast-1 | docker login --username AWS --password-stdin \u0026lt;aws account_id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com Push the docker image to ECR. docker push \u0026lt;aws account_id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/ai-challenge-2024:keyframe-matcher Create Task Definition Click on Task Definitions in the left navigation pane. Click on Create new Task Definition button. Select Create new task with JSON Paste this json in the Task Definition editor. { \u0026#34;containerDefinitions\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;keyframe-matcher-container-min\u0026#34;, \u0026#34;image\u0026#34;: \u0026#34;\u0026lt;aws account id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/ai-challenge-2024:keyframe-matcher\u0026#34;, \u0026#34;cpu\u0026#34;: 512, \u0026#34;memory\u0026#34;: 2048, \u0026#34;portMappings\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;80\u0026#34;, \u0026#34;containerPort\u0026#34;: 80, \u0026#34;hostPort\u0026#34;: 80, \u0026#34;protocol\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;appProtocol\u0026#34;: \u0026#34;http\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;433\u0026#34;, \u0026#34;containerPort\u0026#34;: 443, \u0026#34;hostPort\u0026#34;: 443, \u0026#34;protocol\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;appProtocol\u0026#34;: \u0026#34;http\u0026#34; } ], \u0026#34;essential\u0026#34;: true, \u0026#34;environment\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;FOLDER_PREFIX\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;VIDEO_KEY\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;BUCKET_NAME\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;\u0026#34; } ], \u0026#34;logConfiguration\u0026#34;: { \u0026#34;logDriver\u0026#34;: \u0026#34;awslogs\u0026#34;, \u0026#34;options\u0026#34;: { \u0026#34;awslogs-group\u0026#34;: \u0026#34;/ecs/keyframe-matcher-definition-min\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;non-blocking\u0026#34;, \u0026#34;awslogs-create-group\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;max-buffer-size\u0026#34;: \u0026#34;25m\u0026#34;, \u0026#34;awslogs-region\u0026#34;: \u0026#34;ap-southeast-1\u0026#34;, \u0026#34;awslogs-stream-prefix\u0026#34;: \u0026#34;ecs\u0026#34; }, \u0026#34;secretOptions\u0026#34;: [] }, \u0026#34;systemControls\u0026#34;: [] } ], \u0026#34;family\u0026#34;: \u0026#34;keyframe-matcher-definition-min\u0026#34;, \u0026#34;taskRoleArn\u0026#34;: \u0026#34;arn:aws:iam::\u0026lt;aws account id\u0026gt;:role/TaskRole\u0026#34;, \u0026#34;executionRoleArn\u0026#34;: \u0026#34;arn:aws:iam::\u0026lt;aws account id\u0026gt;:role/TaskRole\u0026#34;, \u0026#34;networkMode\u0026#34;: \u0026#34;awsvpc\u0026#34;, \u0026#34;revision\u0026#34;: 1, \u0026#34;status\u0026#34;: \u0026#34;ACTIVE\u0026#34;, \u0026#34;compatibilities\u0026#34;: [ \u0026#34;EC2\u0026#34;, \u0026#34;FARGATE\u0026#34; ], \u0026#34;requiresCompatibilities\u0026#34;: [ \u0026#34;FARGATE\u0026#34; ], \u0026#34;cpu\u0026#34;: \u0026#34;512\u0026#34;, \u0026#34;memory\u0026#34;: \u0026#34;2048\u0026#34;, \u0026#34;runtimePlatform\u0026#34;: { \u0026#34;cpuArchitecture\u0026#34;: \u0026#34;X86_64\u0026#34;, \u0026#34;operatingSystemFamily\u0026#34;: \u0026#34;LINUX\u0026#34; }, } The core configuration specifying how the container runs within the task:\nContainer Definitions\nname: keyframe-matcher-container-min – The name of the container.\nimage: \u0026lt;aws account id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/ai-challenge-2024:keyframe-matcher – The Docker image stored in Amazon ECR that the container will use.\ncpu: 512 – Allocates 0.5 vCPUs to the container.\nmemory: 2048 – Allocates 2 GB of memory to the container.\nportMappings:\ncontainerPort: 80 – Exposes port 80 for HTTP traffic. containerPort: 433 – Exposes port 433 for traffic (note: may need correction to 443 for HTTPS). essential: true – Indicates that the container is critical for the task; if this container stops, the entire task will stop.\nEnvironment Variables Environment variables passed to the container to configure behavior:\nFOLDER_PREFIX: \u0026quot;\u0026quot; – The prefix for the S3 folder containing keyframes. VIDEO_KEY: \u0026quot;\u0026quot; – The S3 key for the video file to process. BUCKET_NAME: \u0026quot;\u0026quot; – The name of the S3 bucket containing the video and keyframes. Logging Configuration Sets up logging to AWS CloudWatch Logs for monitoring and debugging:\nlogDriver: awslogs – Uses the AWS Logs driver to send logs to CloudWatch. awslogs-group: /ecs/keyframe-matcher-definition-min – Specifies the CloudWatch Logs group where logs are stored. awslogs-create-group: true – Automatically creates the log group if it does not exist. max-buffer-size: 25m – Specifies the maximum buffer size for logs. awslogs-region: ap-southeast-1 – Sets the AWS region for logging. awslogs-stream-prefix: ecs – Adds a prefix to log streams to help identify them easily. Task-Level Settings\nfamily: \u0026quot;keyframe-matcher-definition-min\u0026quot; – The family name of the task, used to identify it in ECS. taskRoleArn: arn:aws:iam::\u0026lt;aws account id\u0026gt;:role/TaskRole – Specifies the IAM role that grants the task permissions to interact with AWS services. executionRoleArn: arn:aws:iam::\u0026lt;aws account id\u0026gt;:role/TaskRole – Specifies the IAM role used by the ECS agent to pull images and publish logs. Network Configuration\nnetworkMode: awsvpc – Uses the AWS VPC network mode, allowing the task to have its own network interfaces, security groups, and elastic network interfaces. requiresCompatibilities: [\u0026quot;FARGATE\u0026quot;] – Specifies that the task requires Fargate launch type. Resource Configuration\ncpu: \u0026quot;512\u0026quot; – Allocates 0.5 vCPUs to the task. memory: \u0026quot;2048\u0026quot; – Allocates 2 GB of memory to the task. ephemeralStorage sizeInGiB: 21 – Provides 21 GB of ephemeral storage for temporary data generated by the task. Platform Configuration\nruntimePlatform: cpuArchitecture: X86_64 – Specifies the CPU architecture. operatingSystemFamily: LINUX – Specifies the operating system family used. After pasting the JSON, click on Create button. We have successfully created a task definition for extracting keyframes from videos.\n3 Run Task to Extract Keyframes 3.1 Prepare Script to Run Task Create run-task.py in the ecr-extract-keyframes directory. This script will run the task definition to extract keyframes from a video file.\nimport os import boto3 s3_client = boto3.client(\u0026#34;s3\u0026#34;) ecs_client = boto3.client(\u0026#34;ecs\u0026#34;) def lambda_handler(event, context): cluster_name = os.environ[\u0026#34;ECS_CLUSTER_NAME\u0026#34;] task_definition = os.environ[\u0026#34;TASK_DEFINITION\u0026#34;] subnet_ids = os.environ[\u0026#34;SUBNET_IDS\u0026#34;] security_group_id = os.environ[\u0026#34;SECURITY_GROUP_ID\u0026#34;] container_name = os.environ[\u0026#34;CONTAINER_NAME\u0026#34;] network_config = { \u0026#34;awsvpcConfiguration\u0026#34;: { \u0026#34;subnets\u0026#34;: subnet_ids, \u0026#34;securityGroups\u0026#34;: [security_group_id], \u0026#34;assignPublicIp\u0026#34;: \u0026#34;ENABLED\u0026#34;, } } FOLDERS = [] response = s3.list_objects_v2(Bucket=BUCKET_NAME, Prefix=PREFIX, Delimiter=\u0026#39;/\u0026#39;) # Get the subfolders in the bucket if \u0026#39;CommonPrefixes\u0026#39; in response: subfolders = [prefix.get(\u0026#39;Prefix\u0026#39;) for prefix in response[\u0026#39;CommonPrefixes\u0026#39;]] for subfolder in subfolders: FOLDERS.append(subfolder) else: print(\u0026#34;No subfolders found.\u0026#34;) for folder in FOLDERS: run_task_input = { \u0026#34;cluster\u0026#34;: cluster_name, \u0026#34;launchType\u0026#34;: \u0026#34;FARGATE\u0026#34;, \u0026#34;taskDefinition\u0026#34;: task_definition, \u0026#34;networkConfiguration\u0026#34;: network_config, \u0026#34;overrides\u0026#34;: { \u0026#34;containerOverrides\u0026#34;: [ { \u0026#34;name\u0026#34;: container_name, \u0026#34;environment\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;BUCKET_NAME\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;ai-challenge-2024\u0026#34;, }, { \u0026#34;name\u0026#34;: \u0026#34;FOLDER_PREFIX\u0026#34;, \u0026#34;value\u0026#34;: folder, }, { \u0026#34;name\u0026#34;: \u0026#34;VIDEO_KEY\u0026#34;, \u0026#34;value\u0026#34;: f\u0026#34;video/{folder.split(\u0026#34;/\u0026#34;)[1]}.mp4\u0026#34;, }, ], } ] }, } response = ecs_client.run_task(**run_task_input) return { \u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: f\u0026#39;Task created successfully with Task ARN: {response[\u0026#34;tasks\u0026#34;][0][\u0026#34;taskArn\u0026#34;]}\u0026#39;, } if __name__ == \u0026#34;__main__\u0026#34;: event = {} context = None lambda_handler(event, context) Environment Variables:\nECS_CLUSTER_NAME: The name of the ECS cluster where the task will run. TASK_DEFINITION: The ARN of the task definition created in the previous step. SUBNET_IDS: The ID of the subnets where the task will run. SECURITY_GROUP_ID: The ID of the security group for the task. CONTAINER_NAME: The name of the container in the task definition. Example Values:\nECS_CLUSTER_NAME: ai-challenge-2024-cluster TASK_DEFINITION: arn:aws:ecs:ap-southeast-1:\u0026lt;aws account id\u0026gt;:task-definition/keyframe-matcher-definition-min:1 SUBNET_IDS: [\u0026quot;subnet-0a1b2c3d4e5f6g7h\u0026quot;,\u0026quot;subnet-1a2b3c4d5e6f7g8\u0026quot;] SECURITY_GROUP_ID: sg-0123456789abcdef0 CONTAINER_NAME: keyframe-matcher-container-min 3.2 Run Task By Local CLI Run the script to create a task to extract keyframes from the video file.\npython run-task.py The script will create a task in the ECS cluster to extract keyframes from the video file. You can monitor the task status in the ECS console.\n3.3 Verify Keyframes Extraction After the task completes, you can verify that the keyframes have been extracted and updated with metadata in the S3 bucket.\nNavigate to the S3 console. Open the bucket ai-challenge-2024. Check the keyframes folder for the extracted keyframes. Verify that the keyframes have been updated with metadata in the S3 console. Video Key: The S3 key of the video file. Frame Number: The frame number in the video where the keyframe was found. Check results in the metadata folder for the CSV file containing the keyframe metadata. "
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/4-process-data/4.2-embedding-processing-sagemaker/",
	"title": "Embedding Processing with SageMaker",
	"tags": [],
	"description": "Learn how to build a Semantic Video Search Vector Database using AWS services such as SageMaker, S3, OpenSearch, ECS Fargate, and Lambda.",
	"content": "1.Prepare Script for Embedding Processing Create a folder embedding-processing and navigate to it. |-- main.ipynb |-- requirements.txt `-- script.py Create a main.ipynb file in the embedding-processing directory. Import Libraries import sagemaker import boto3 from PIL import Image from io import BytesIO import matplotlib.pyplot as plt import sagemaker from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput Set Up SageMaker Session s3 = boto3.client(\u0026#39;s3\u0026#39;) sess = sagemaker.Session() BUCKET_NAME = \u0026#34;ai-challenge-2024\u0026#34; PREFIX = \u0026#34;keyframes/\u0026#34; OUTPUT_PREFIX = \u0026#34;keyframes-processed/\u0026#34; FOLDERS = []\rresponse = s3.list_objects_v2(Bucket=BUCKET_NAME, Prefix=PREFIX, Delimiter=\u0026#39;/\u0026#39;)\r# Get the subfolders in the bucket\rif \u0026#39;CommonPrefixes\u0026#39; in response:\rsubfolders = [prefix.get(\u0026#39;Prefix\u0026#39;) for prefix in response[\u0026#39;CommonPrefixes\u0026#39;]]\rfor subfolder in subfolders:\rFOLDERS.append(subfolder)\relse:\rprint(\u0026#34;No subfolders found.\u0026#34;) Show Sample Image # Get exmaple file in each subfolder example_folder = FOLDERS[0] files = s3.list_objects_v2(Bucket=BUCKET_NAME, Prefix=example_folder) plt.figure(figsize=(20, 10)) for i in range(1, 5): example_file = files[\u0026#39;Contents\u0026#39;][i][\u0026#39;Key\u0026#39;] example_img = s3.get_object(Bucket=BUCKET_NAME, Key=example_file)[\u0026#34;Body\u0026#34;].read() img = Image.open(BytesIO(example_img)) plt.subplot(1, 4, i) plt.imshow(img) plt.show() Script Processor %%writefile script.py import os import sys import subprocess subprocess.check_call( [ sys.executable, \u0026#34;-m\u0026#34;, \u0026#34;pip\u0026#34;, \u0026#34;install\u0026#34;, \u0026#34;-r\u0026#34;, \u0026#34;/opt/ml/processing/code/requirements.txt\u0026#34;, ] ) import torch from sentence_transformers import SentenceTransformer from PIL import Image import numpy def processor(input_dir, output_dir): print(\u0026#34;Loading model.....\u0026#34;) model = SentenceTransformer(\u0026#34;clip-ViT-B-32\u0026#34;) print(\u0026#34;Model loaded\u0026#34;) device = \u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34; model = model.to(device) print(f\u0026#34;Using device: {device}\u0026#34;) folders = os.listdir(input_dir) for folder in folders: # Ignore : \u0026#39;/opt/ml/processing/input/code/script.py\u0026#39; if folder == \u0026#34;code\u0026#34;: continue image_paths = os.listdir(os.path.join(input_dir, folder)) images = [] for image_path in image_paths: image = Image.open(os.path.join(input_dir, folder, image_path)) images.append(image) embeddings = model.encode(images) numpy.save(os.path.join(output_dir, f\u0026#34;{folder}.npy\u0026#34;), embeddings) print(f\u0026#34;Embeddings for {folder} saved\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: input_dir = \u0026#34;/opt/ml/processing/input\u0026#34; output_dir = \u0026#34;/opt/ml/processing/output\u0026#34; # Local testing # input_dir = \u0026#34;./dataset/keyframes\u0026#34; # output_dir = \u0026#34;./dataset/output\u0026#34; print(\u0026#34;Starting processing.....\u0026#34;) processor(input_dir, output_dir) print(\u0026#34;Processing complete\u0026#34;) Requirements.txt %%writefile requirements.txt sentence_transformers pillow Upload requirements.txt to S3 s3.upload_file(\u0026#34;requirements.txt\u0026#34;, BUCKET_NAME, \u0026#34;code/requirements.txt\u0026#34;) Start processing job role = sagemaker.get_execution_role() image_uri = sagemaker.image_uris.retrieve( framework=\u0026#39;pytorch\u0026#39;, region=sess.boto_region_name, version=\u0026#39;1.9\u0026#39;, py_version=\u0026#39;py38\u0026#39;, instance_type=\u0026#39;ml.m5.xlarge\u0026#39;, image_scope=\u0026#39;training\u0026#39; ) script_processor = ScriptProcessor( image_uri=image_uri, command=[\u0026#39;python3\u0026#39;], role=role, instance_count=1, instance_type=\u0026#39;ml.m5.xlarge\u0026#39;, sagemaker_session=sess ) input_s3_uri = \u0026#39;s3://{}/{}/\u0026#39;.format(BUCKET_NAME, PREFIX) output_s3_uri = \u0026#39;s3://{}/{}/\u0026#39;.format(BUCKET_NAME, OUTPUT_PREFIX) processing_inputs = [ ProcessingInput( source=input_s3_uri, destination=\u0026#39;/opt/ml/processing/input\u0026#39; ), ProcessingInput( source=\u0026#39;s3://{}/code/\u0026#39;.format(BUCKET_NAME), destination=\u0026#39;/opt/ml/processing/code\u0026#39; ) ] processing_outputs = [ ProcessingOutput( source=\u0026#39;/opt/ml/processing/output\u0026#39;, destination=output_s3_uri ) ] script_processor.run( code=\u0026#39;script.py\u0026#39;, inputs=processing_inputs, outputs=processing_outputs, logs=True ) Note: If you encounter an error related to the quota limit, you can request a limit increase by following the instructions.\n2.Monitor Processing Job You can monitor the processing job by navigating to the SageMaker console and selecting the Processing jobs tab. You will see the job status, logs, and other details related to the processing job.\n3.Check Output Data in S3 Once the processing job is complete, you can check the output data in the S3 bucket. Navigate to the S3 console and locate the embeddings folder to view the processed embeddings.\n"
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/5-vectordb-opensearch/",
	"title": "Implementing OpenSearch for Vector Database",
	"tags": [],
	"description": "Learn how to build a Semantic Video Search Vector Database using AWS services such as SageMaker, S3, OpenSearch, ECS Fargate, and Lambda.",
	"content": "Overview Welcome to the \u0026ldquo;Implementing OpenSearch for Vector Database\u0026rdquo; module! In this module, we will guide you through setting up and using OpenSearch as a vector database for storing and querying video vectors. You will learn how to configure OpenSearch, index video features, and perform semantic searches efficiently.\nContents Set Up OpenSearch Cluster Create Index and Indexing Data With Python SDK Query by Text "
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/5-vectordb-opensearch/5.1-set-up-cluster/",
	"title": "Set Up OpenSearch Cluster",
	"tags": [],
	"description": "Learn how to build a Semantic Video Search Vector Database using AWS services such as SageMaker, S3, OpenSearch, ECS Fargate, and Lambda.",
	"content": "Create an OpenSearch Domain Navigate to OpenSearch by clicking on the Services menu, under the Analytics section.\nClick on Create domain button.\nIn the Name :\nDomain name: Enter semantic-search-domain Domain creation method: Select Standard create\nTemplates: Select Dev/test\nIn the Deployment option(s):\nChoose Domain without standby Select 1AZ In the Data nodes:\nInstance type: Select t3.small.search Number of data nodes: Enter 1 Storage type: Select EBS with 10GB storage of General Purpose SSD (gp3) Network mode : Select Public access\nFine-grained access control:\nSelect Create master user Master user name: Enter admin Master password: Enter \u0026lt;password\u0026gt; Access policy:\nSelect Allow open access to the domain Click on Create domain button\nWait for the domain to be created. Once the domain is created, you will see the domain status as Active.\n"
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/5-vectordb-opensearch/5.2-create-index-and-indexing-data/",
	"title": "Create Index and Indexing Data With Python SDK",
	"tags": [],
	"description": "Learn how to build a Semantic Video Search Vector Database using AWS services such as SageMaker, S3, OpenSearch, ECS Fargate, and Lambda.",
	"content": "1 Prepare Script to Create Index and Indexing Data Create a Python script to create an index and index data in the OpenSearch domain. The script will perform the following tasks: Delete the index if it exists. Create an index with KNN settings. Create a map embedding from the embeddings directory. Bulk add documents to the index from the map embedding jsonl file. Before running the script, make sure to download the embeddings from the s3 bucket to the local machine. The embeddings are stored in the embeddings directory. import os import json import numpy from opensearchpy import OpenSearch, helpers , RequestsHttpConnection class SemanticSearch: def __init__(self, host, port, user, password, index_name): self.client = OpenSearch( hosts=[{\u0026#34;host\u0026#34;: host, \u0026#34;port\u0026#34;: port}], http_auth=(user, password), use_ssl=True, verify_certs=True, connection_class=RequestsHttpConnection, timeout = 120, max_retries = 5, retry_on_timeout = True ) self.index_name = index_name def delete_index(self): try: response = self.client.indices.delete(index=self.index_name) print(f\u0026#34;Index \u0026#39;{self.index_name}\u0026#39; deleted successfully:\u0026#34;, response) except Exception as e: print(f\u0026#34;Error deleting index \u0026#39;{self.index_name}\u0026#39;:\u0026#34;, e) def create_index(self): index_body = { \u0026#34;settings\u0026#34;: {\u0026#34;index\u0026#34;: {\u0026#34;knn\u0026#34;: True}}, \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;image_embedding\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;knn_vector\u0026#34;, \u0026#34;dimension\u0026#34;: 512, \u0026#34;method\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hnsw\u0026#34;, \u0026#34;engine\u0026#34;: \u0026#34;faiss\u0026#34;, \u0026#34;space_type\u0026#34;: \u0026#34;l2\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;ef_construction\u0026#34;: 256, \u0026#34;m\u0026#34;: 48, }, }, }, \u0026#34;video\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;}, \u0026#34;image\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34;}, } }, } # Tạo index response = self.client.indices.create(index=self.index_name, body=index_body) print(f\u0026#34;Index created: {response}\u0026#34;) def create_map_embedding(self, embedding_dir): files = os.listdir(embedding_dir) map_embedding = [] for file in files: embeddings = numpy.load(f\u0026#34;{embedding_dir}/{file}\u0026#34;) for i, embedding in enumerate(embeddings): map_embedding.append( { \u0026#34;video\u0026#34;: file, \u0026#34;image\u0026#34;: i + 1, \u0026#34;image_embedding\u0026#34;: embedding.tolist(), } ) # save to jsonl file with open(\u0026#34;map_embedding.jsonl\u0026#34;, \u0026#34;w\u0026#34;) as f: for i, doc in enumerate(map_embedding): f.write( json.dumps( { \u0026#34;_op_type\u0026#34;: \u0026#34;index\u0026#34;, \u0026#34;_index\u0026#34;: self.index_name, \u0026#34;_id\u0026#34;: i + 1, \u0026#34;_source\u0026#34;: { \u0026#34;image_embedding\u0026#34;: doc[\u0026#34;image_embedding\u0026#34;], \u0026#34;image\u0026#34;: doc[\u0026#34;image\u0026#34;], \u0026#34;video\u0026#34;: doc[\u0026#34;video\u0026#34;], }, } ) ) f.write(\u0026#34;\\n\u0026#34;) def bulk_add_documents(self, file_path): actions = [] with open(file_path, \u0026#34;r\u0026#34;) as f: for line in f: document = json.loads(line.strip()) actions.append(document) if len(actions) \u0026gt;= 1000: helpers.bulk(self.client, actions) print(\u0026#34;Batch added: \u0026#34; , len(actions)) actions = [] if actions: helpers.bulk(self.client, actions) # Sử dụng class SemanticSearch host = \u0026#34;\u0026lt;your-opensearch-endpoint\u0026gt;\u0026#34; port = 443 user = \u0026#34;\u0026lt;your-opensearch-user\u0026gt;\u0026#34; password = \u0026#34;\u0026lt;your-opensearch-password\u0026gt;\u0026#34; index_name = \u0026#34;semantic-index\u0026#34; search_system = SemanticSearch(host, port, user, password, index_name) search_system.delete_index() search_system.create_index() search_system.create_map_embedding(\u0026#34;embeddings\u0026#34;) search_system.bulk_add_documents(\u0026#34;map_embedding.jsonl\u0026#34;) Explain the code: delete_index() : Xóa index nếu tồn tại. create_index() : Tạo index với cấu hình KNN (dimension = 512, method = hnsw, engine = faiss, space_type = l2). create_map_embedding() : Tạo map embedding từ các file embedding trong thư mục embeddings theo định dạng jsonl. bulk_add_documents() : Thêm các documents vào index từ file jsonl theo batch size 1000. Monitoring the Cluster 1. Check Cluster Health Navigate to OpenSearch by clicking on the Domain menu, click on the domain name semantic-search-domain. In the Overview tab, you can see the Cluster health status. After indexing the data, we will see total dcouments is 105k "
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/5-vectordb-opensearch/5.3-query-by-text/",
	"title": "Query by Text",
	"tags": [],
	"description": "Learn how to build a Semantic Video Search Vector Database using AWS services such as SageMaker, S3, OpenSearch, ECS Fargate, and Lambda.",
	"content": "1 Script to Query by Text 1.1 Set up client and model embedding. # code for testing host = \u0026#34;\u0026lt;your opensearch domain\u0026gt;\u0026#34; port = 443 user = \u0026#34;\u0026lt;your master user\u0026gt;\u0026#34; password = \u0026#34;\u0026lt;your master password\u0026gt;\u0026#34; client = OpenSearch( hosts=[{\u0026#34;host\u0026#34;: host, \u0026#34;port\u0026#34;: port}], http_auth=(user, password), use_ssl=True, verify_certs=True, connection_class=RequestsHttpConnection, timeout = 60, # max_retries = 5, # retry_on_timeout = True ) s3 = boto3.client(\u0026#34;s3\u0026#34;) BUCKET_NAME = \u0026#34;ai-challenge-2024\u0026#34; FOLDER_NAME = \u0026#34;keyframes\u0026#34; model = SentenceTransformer(\u0026#34;clip-ViT-B-32\u0026#34;) 1.2 Query by Text def query(client , model , text , k=5): index_name = \u0026#34;semantic-index\u0026#34; query_vector = model.encode(text) search_body = { \u0026#34;size\u0026#34;: k, \u0026#34;query\u0026#34;: { \u0026#34;knn\u0026#34;: { \u0026#34;image_embedding\u0026#34;: { \u0026#34;vector\u0026#34;: query_vector.tolist(), \u0026#34;k\u0026#34;: k, } } }, } result = [] # { # \u0026#34;image\u0026#34; : 1, # \u0026#34;video\u0026#34; : \u0026#34;video1.mp4\u0026#34; # \u0026#34;score\u0026#34; : 1 # } response = client.search(index=index_name, body=search_body) response = response[\u0026#34;hits\u0026#34;][\u0026#34;hits\u0026#34;] for hit in response: image = hit[\u0026#34;_source\u0026#34;][\u0026#34;image\u0026#34;] video = hit[\u0026#34;_source\u0026#34;][\u0026#34;video\u0026#34;] score = hit[\u0026#34;_score\u0026#34;] result.append({\u0026#34;image\u0026#34; : image , \u0026#34;video\u0026#34; : video , \u0026#34;score\u0026#34; : score}) return result result_query = query(client=client , model=model , text=\u0026#34;A drowning prevention drill is taking place. Flooding occurs, and soldiers are deployed to schools to clean up the floodwaters\u0026#34; , k=5) print(result_query) 1.3 Visualize the Result def convert_to_s3_key(video, image): #video L03_V025.npy =\u0026gt; L03_V025 # image 18 =\u0026gt; 018.jpg # image 1 =\u0026gt; 001.jpg video = video.split(\u0026#34;.\u0026#34;)[0] image = str(image).zfill(3) + \u0026#34;.jpg\u0026#34; return video + \u0026#34;/\u0026#34; + image fig = plt.figure(figsize=(20, 10)) for res in result_query: fig.add_subplot(1, 5, result_query.index(res) + 1) img = s3.get_object(Bucket=BUCKET_NAME, Key=f\u0026#34;{FOLDER_NAME}/{convert_to_s3_key(res[\u0026#39;video\u0026#39;],res[\u0026#39;image\u0026#39;])}\u0026#34;)[\u0026#34;Body\u0026#34;].read() img = Image.open(io.BytesIO(img)) plt.imshow(img) plt.show() 2 Test some queries and visualize the results A drowning prevention drill is taking place. Flooding occurs, and soldiers are deployed to schools to clean up the floodwaters A video clip shows mothers taking care of children with chickenpox. Chickenpox causes blisters to appear all over the children\u0026rsquo;s bodies, accompanied by uncomfortable itching. A video clip of an apple orchard owned by a man. The orchard is vast, filled with many ripe red apples, and visitors happily pick apples, putting them into bags to take home. "
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/6-deploy-with-terraform/",
	"title": "Deploy with Terraform",
	"tags": [],
	"description": "Learn how to build a Semantic Video Search Vector Database using AWS services such as SageMaker, S3, OpenSearch, ECS Fargate, and Lambda.",
	"content": "Overview We will deploy a search-based system using an existing OpenSearch domain on AWS, managed via Terraform. The deployment consists of five main modules:\nSetup: This module sets up the foundational infrastructure:\nCreate an ECR (Elastic Container Registry) repository. Build Docker images and push them to the ECR repository. Create a SageMaker endpoint for machine learning tasks. Optionally, create a new OpenSearch domain if you do not wish to use the provided data and domain. Processing Data: This module handles the extraction of keyframes from video data:\nCreate ECS (Elastic Container Service) tasks to process videos and extract keyframes. The keyframes are then stored in an S3 bucket for further processing. Embedding: This module generates vector embeddings from the extracted keyframes:\nUse SageMaker processing jobs to perform embedding generation for the extracted keyframes. The generated embeddings are stored in S3 or directly indexed into OpenSearch. VectorDB: This module focuses on managing the OpenSearch domain:\nPerform indexing of the generated embeddings in the OpenSearch domain. Enable querying of vector data to support semantic search capabilities. CMS (Content Management System): This module deploys a backend service for managing content and search functionalities:\nSet up API Gateway for RESTful APIs. Use Cognito for authentication and user management. S3 for storing static assets and data. CloudFront for content delivery and caching. The system is deployed based on the existing OpenSearch domain and indexed data using these five modules. If you want to use your own video data, you can create a new OpenSearch domain and customize the deployment.\nContent Setup Processing Data Embedding VectorDB CMS "
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/6-deploy-with-terraform/6.1-settup/",
	"title": "Setup",
	"tags": [],
	"description": "Learn how to build a Semantic Video Search Vector Database using AWS services such as SageMaker, S3, OpenSearch, ECS Fargate, and Lambda.",
	"content": "1 Setup Infrastructure 1.1 Create ecr repo ecr-repo resource \u0026#34;aws_ecr_repository\u0026#34; \u0026#34;private_repo\u0026#34; { name = \u0026#34;semantic-repo\u0026#34; tags = var.common_tags } output \u0026#34;ecr_repo_url\u0026#34; { value = aws_ecr_repository.private_repo.repository_url } 1.2 Fectch Opensearch domain data \u0026#34;aws_opensearch_domain\u0026#34; \u0026#34;semantic_search_domain\u0026#34; { domain_name = var.opensearch_domain_name } 1.3 Create VPC ################################# # VPC ################################# resource \u0026#34;aws_vpc\u0026#34; \u0026#34;main\u0026#34; { cidr_block = \u0026#34;172.0.0.0/16\u0026#34; enable_dns_support = true enable_dns_hostnames = true tags = var.common_tags } ################################# # Internet Gateway ################################# resource \u0026#34;aws_internet_gateway\u0026#34; \u0026#34;main\u0026#34; { vpc_id = aws_vpc.main.id tags = var.common_tags } ################################# # Public Subnets ################################# resource \u0026#34;aws_subnet\u0026#34; \u0026#34;public\u0026#34; { count = 2 vpc_id = aws_vpc.main.id cidr_block = \u0026#34;172.0.${count.index}.0/24\u0026#34; map_public_ip_on_launch = true tags = var.common_tags } ################################# # Private Subnets ################################# resource \u0026#34;aws_subnet\u0026#34; \u0026#34;private\u0026#34; { count = 2 vpc_id = aws_vpc.main.id cidr_block = \u0026#34;172.0.${count.index + 10}.0/24\u0026#34; tags = var.common_tags } ################################# # Route Tables ################################# resource \u0026#34;aws_route_table\u0026#34; \u0026#34;public\u0026#34; { vpc_id = aws_vpc.main.id route { cidr_block = \u0026#34;0.0.0.0/0\u0026#34; gateway_id = aws_internet_gateway.main.id } tags = var.common_tags } resource \u0026#34;aws_route_table_association\u0026#34; \u0026#34;public\u0026#34; { count = 2 subnet_id = aws_subnet.public[count.index].id route_table_id = aws_route_table.public.id } resource \u0026#34;aws_route_table\u0026#34; \u0026#34;private\u0026#34; { vpc_id = aws_vpc.main.id tags = var.common_tags } resource \u0026#34;aws_route_table_association\u0026#34; \u0026#34;private\u0026#34; { count = 2 subnet_id = aws_subnet.private[count.index].id route_table_id = aws_route_table.private.id } ################################# # Security Groups ################################# resource \u0026#34;aws_security_group\u0026#34; \u0026#34;default\u0026#34; { vpc_id = aws_vpc.main.id egress { from_port = 0 to_port = 0 protocol = \u0026#34;-1\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } # Allow http traffic ingress { from_port = 80 to_port = 80 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } # Allow https traffic ingress { from_port = 443 to_port = 443 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } # Allow ssh traffic ingress { from_port = 22 to_port = 22 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } tags = var.common_tags } output \u0026#34;vpc_id\u0026#34; { value = aws_vpc.main.id } output \u0026#34;public_subnet_ids\u0026#34; { value = aws_subnet.public[*].id } output \u0026#34;private_subnet_ids\u0026#34; { value = aws_subnet.private[*].id } output \u0026#34;security_group_id\u0026#34; { value = aws_security_group.default.id } 2 Setup ECR Image , Sagemaker Endpoint 2.1 Buid docker image for processing data Create a file Dockerfile in the root directory of the project FROM python:3.9-slim RUN apt-get update \u0026amp;\u0026amp; \\ apt-get install -y ffmpeg \u0026amp;\u0026amp; \\ pip install boto3 COPY extract_keyframes.py /app/extract_keyframes.py WORKDIR /app ENTRYPOINT [\u0026#34;python\u0026#34;, \u0026#34;extract_keyframes.py\u0026#34;] Create a file extract_keyframes.py in the root directory of the project import os import boto3 import subprocess from botocore.exceptions import NoCredentialsError import json S3_BUCKET = os.environ.get(\u0026#39;S3_BUCKET\u0026#39;) INPUT_VIDEO_KEY = os.environ.get(\u0026#39;INPUT_VIDEO_KEY\u0026#39;) OUTPUT_FOLDER_PREFIX = os.environ.get(\u0026#39;OUTPUT_FOLDER_PREFIX\u0026#39;, \u0026#39;output/\u0026#39;) OUTPUT_MAP_FOLDER = \u0026#39;mapkeyframes\u0026#39; s3 = boto3.client(\u0026#39;s3\u0026#39;) lambda_client = boto3.client(\u0026#39;lambda\u0026#39;) def download_from_s3(bucket, key, download_path): try: s3.download_file(bucket, key, download_path) print(f\u0026#34;Downloaded {key} from {bucket}\u0026#34;) except NoCredentialsError: print(\u0026#34;Error: Not authorized\u0026#34;) raise def upload_to_s3(bucket, file_path, s3_key): try: s3.upload_file(file_path, bucket, s3_key) print(f\u0026#34;Uploaded {file_path} to {bucket}/{s3_key}\u0026#34;) except NoCredentialsError: print(\u0026#34;Error: Not authorized\u0026#34;) raise def extract_keyframes(video_path, output_folder): if not os.path.exists(output_folder): os.makedirs(output_folder) cmd = [ \u0026#39;ffmpeg\u0026#39;, \u0026#39;-i\u0026#39;, video_path, \u0026#39;-vf\u0026#39;, \u0026#39;select=eq(pict_type\\\\,I)\u0026#39;, \u0026#39;-vsync\u0026#39;, \u0026#39;vfr\u0026#39;, \u0026#39;-q:v\u0026#39;, \u0026#39;2\u0026#39;, f\u0026#39;{output_folder}/%03d.jpg\u0026#39; ] subprocess.run(cmd) def generate_map_csv(keyframes_folder, csv_path, video_name): with open(csv_path, \u0026#39;w\u0026#39;) as f: f.write(\u0026#39;FrameNumber,ImagePath\\n\u0026#39;) for image in sorted(os.listdir(keyframes_folder)): if image.endswith(\u0026#39;.jpg\u0026#39;): frame_number = int(image.split(\u0026#39;.\u0026#39;)[0]) image_path = os.path.join(keyframes_folder, image) f.write(f\u0026#34;{frame_number},{image_path}\\n\u0026#34;) print(f\u0026#34;Created {csv_path}\u0026#34;) def invoke_second_lambda(bucket_name, video_name): payload = { \u0026#39;bucket_name\u0026#39;: bucket_name, \u0026#39;video_name\u0026#39;: video_name } print(f\u0026#34;Invoke second lambda with payload: {payload}\u0026#34;) response = lambda_client.invoke( FunctionName=\u0026#34;embedding_data\u0026#34;, InvocationType=\u0026#39;Event\u0026#39;, Payload=json.dumps(payload) ) print(f\u0026#34;Start Embedding ....: {response}\u0026#34;) def main(): # Download video video_name = os.path.basename(INPUT_VIDEO_KEY) video_path = f\u0026#39;/tmp/{video_name}\u0026#39; download_from_s3(S3_BUCKET, INPUT_VIDEO_KEY, video_path) output_folder_name = os.path.splitext(video_name)[0] output_folder = f\u0026#39;/tmp/{output_folder_name}\u0026#39; extract_keyframes(video_path, output_folder) csv_filename = f\u0026#39;map-keyframe-{output_folder_name}.csv\u0026#39; csv_path = f\u0026#39;/tmp/{csv_filename}\u0026#39; generate_map_csv(output_folder, csv_path, output_folder_name) # Upload keyframes and csv to S3 for image in os.listdir(output_folder): upload_to_s3(S3_BUCKET, os.path.join(output_folder, image), f\u0026#39;{OUTPUT_FOLDER_PREFIX}{output_folder_name}/{image}\u0026#39;) upload_to_s3(S3_BUCKET, csv_path, f\u0026#39;{OUTPUT_MAP_FOLDER}/{csv_filename}\u0026#39;) # Invoke second lambda invoke_second_lambda(S3_BUCKET, output_folder_name) if __name__ == \u0026#34;__main__\u0026#34;: main() Build the docker image cd to the root directory of the project and run the following command @echo \u0026#34;Building ECS Video\u0026#34; docker build -t ecs-video -f Dockerfile . Push the docker image to ECR You can go to the ECR repository and follow the instructions to push the docker image to ECR or you can run the following command @echo \u0026#34;Pushing ECS Video to ECR\u0026#34; aws ecr get-login-password --region ap-southeast-1 | docker login --username AWS --password-stdin \u0026lt;aws account id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com docker tag ecs-video:latest \u0026lt;aws account id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/semantic-repo:ecs-video docker push \u0026lt;aws account id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/semantic-repo:ecs-video @echo \u0026#34;Pushed ECS Video to ECR\u0026#34; 2.2 Create Sagemaker Endpoint Structure of the code |-- code | |-- inference_code.py | `-- requirements.txt `-- setup.py Create a file inference_code.py in the code folder from sentence_transformers import SentenceTransformer import json import os def model_fn(model_dir): model_path = os.path.join(model_dir, \u0026#34;model\u0026#34;) model = SentenceTransformer(model_path) return model def input_fn(request_body, request_content_type): if request_content_type == \u0026#34;application/json\u0026#34;: input_data = json.loads(request_body) else: return request_body return input_data[\u0026#34;text\u0026#34;] def predict_fn(input_data, model): embeddings = model.encode(input_data) return embeddings def output_fn(prediction, content_type): if content_type == \u0026#34;application/json\u0026#34;: return json.dumps({\u0026#34;embeddings\u0026#34;: prediction.tolist()}) else: return \u0026#34;content type not supported\u0026#34; Create a file requirements.txt in the code folder sentence_transformers Create a file setup.py in the root directory of the project. Before running the setup.py, you need create a role for the sagemaker endpoint to access the S3 bucket sagemaker-local from sentence_transformers import SentenceTransformer import tarfile from sagemaker.pytorch import PyTorchModel import time import os # Wait for about 5 minutes model = SentenceTransformer(\u0026#39;clip-ViT-B-32\u0026#39;) model.save(\u0026#39;model\u0026#39;) model_path = \u0026#39;model/\u0026#39; code_path = \u0026#39;code/\u0026#39; # Wait for about 5 minutes zipped_model_path = os.path.join(model_path, \u0026#34;model.tar.gz\u0026#34;) with tarfile.open(zipped_model_path, \u0026#34;w:gz\u0026#34;) as tar: tar.add(model_path) tar.add(code_path) # Wait for about 20 minutes endpoint_name = \u0026#34;clip-model-\u0026#34; + time.strftime(\u0026#34;%Y-%m-%d-%H-%M-%S\u0026#34;, time.gmtime()) model = PyTorchModel( entry_point=\u0026#34;inference_code.py\u0026#34;, model_data=zipped_model_path, role=\u0026#34;arn:aws:iam::\u0026lt;aws account id\u0026gt;:role/sagemaker-local\u0026#34;, framework_version=\u0026#34;1.5\u0026#34;, py_version=\u0026#34;py3\u0026#34;, ) predictor = model.deploy( initial_instance_count=1, instance_type=\u0026#34;ml.m5.xlarge\u0026#34;, endpoint_name=endpoint_name ) # Wait total of 30 minutes Run the setup.py file python setup.py Wait for about 30 minutes for the endpoint to be created\n"
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/6-deploy-with-terraform/6.2-processing-data/",
	"title": "Processing Data",
	"tags": [],
	"description": "Learn how to build a Semantic Video Search Vector Database using AWS services such as SageMaker, S3, OpenSearch, ECS Fargate, and Lambda.",
	"content": "1. Create ECS Cluster and Task Definition locals { container_name = \u0026#34;video-processing-container\u0026#34; } ################################# # ECS Cluster ################################# resource \u0026#34;aws_ecs_cluster\u0026#34; \u0026#34;video_processing\u0026#34; { name = \u0026#34;video-processing\u0026#34; tags = var.common_tags } ################################# # ECS Task Definition ################################# resource \u0026#34;aws_ecs_task_definition\u0026#34; \u0026#34;video_processing\u0026#34; { family = \u0026#34;video-processing\u0026#34; execution_role_arn = aws_iam_role.ecs_task_execution_role.arn task_role_arn = aws_iam_role.ecs_task_role.arn network_mode = \u0026#34;awsvpc\u0026#34; requires_compatibilities = [\u0026#34;FARGATE\u0026#34;] cpu = 2048 memory = 6144 depends_on = [ aws_ecs_cluster.video_processing ] container_definitions = jsonencode([ { name = local.container_name image = var.ecs_video_image cpu = 2048 memory = 6144 # Logging Configuration logConfiguration = { logDriver = \u0026#34;awslogs\u0026#34; options = { \u0026#34;awslogs-group\u0026#34; = \u0026#34;/ecs/video-processing\u0026#34; \u0026#34;awslogs-region\u0026#34; = \u0026#34;ap-southeast-1\u0026#34; \u0026#34;awslogs-stream-prefix\u0026#34; = \u0026#34;ecs\u0026#34; \u0026#34;awslogs-create-group\u0026#34; = \u0026#34;true\u0026#34; \u0026#34;max-buffer-size\u0026#34; = \u0026#34;25m\u0026#34; \u0026#34;mode\u0026#34; = \u0026#34;non-blocking\u0026#34; } } # Port Mapping Configuration portMappings = [ { containerPort = 80 hostPort = 80 protocol = \u0026#34;tcp\u0026#34; }, { containerPort = 443 hostPort = 443 protocol = \u0026#34;tcp\u0026#34; } ] essential = true environment = [ { name = \u0026#34;S3_BUCKET\u0026#34; value = \u0026#34;your-bucket-name\u0026#34; }, { name = \u0026#34;INPUT_VIDEO_KEY\u0026#34; value = \u0026#34;your-video-key\u0026#34; } ] } ]) } 2. Create Role for ECS Task and Role for Lambda ################################# # Role for Lambda ################################# data \u0026#34;aws_iam_policy_document\u0026#34; \u0026#34;lambda_assume_role\u0026#34; { statement { actions = [\u0026#34;sts:AssumeRole\u0026#34;] principals { type = \u0026#34;Service\u0026#34; identifiers = [\u0026#34;lambda.amazonaws.com\u0026#34;] } } } resource \u0026#34;aws_iam_role\u0026#34; \u0026#34;lambda_role\u0026#34; { name = \u0026#34;lambda_s3_ecs_role\u0026#34; assume_role_policy = data.aws_iam_policy_document.lambda_assume_role.json } resource \u0026#34;aws_iam_policy\u0026#34; \u0026#34;lambda_policy\u0026#34; { name = \u0026#34;lambda_s3_ecs_policy\u0026#34; policy = jsonencode({ \u0026#34;Version\u0026#34; : \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34; : [ { \u0026#34;Effect\u0026#34; : \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34; : [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:ListBucket\u0026#34; ], \u0026#34;Resource\u0026#34; : [ \u0026#34;arn:aws:s3:::${var.bucket_video_name}\u0026#34;, \u0026#34;arn:aws:s3:::${var.bucket_video_name}/*\u0026#34; ] }, { \u0026#34;Effect\u0026#34; : \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34; : [ \u0026#34;ecs:RunTask\u0026#34;, \u0026#34;ecs:DescribeTasks\u0026#34;, \u0026#34;ecs:DescribeTaskDefinition\u0026#34;, \u0026#34;iam:PassRole\u0026#34; ], \u0026#34;Resource\u0026#34; : \u0026#34;*\u0026#34; }, { \u0026#34;Effect\u0026#34; : \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34; : [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34; : \u0026#34;*\u0026#34; } ] }) depends_on = [ aws_iam_role.lambda_role, aws_s3_bucket.video ] } resource \u0026#34;aws_iam_role_policy_attachment\u0026#34; \u0026#34;lambda_role_attach\u0026#34; { role = aws_iam_role.lambda_role.name policy_arn = aws_iam_policy.lambda_policy.arn depends_on = [ aws_iam_policy.lambda_policy ] } ################################# # ECS Task Execution Role ################################# data \u0026#34;aws_iam_policy_document\u0026#34; \u0026#34;ecs_task_execution_assume_role\u0026#34; { statement { actions = [\u0026#34;sts:AssumeRole\u0026#34;] principals { type = \u0026#34;Service\u0026#34; identifiers = [\u0026#34;ecs-tasks.amazonaws.com\u0026#34;] } } } resource \u0026#34;aws_iam_role\u0026#34; \u0026#34;ecs_task_execution_role\u0026#34; { name = \u0026#34;ecs_task_execution_role\u0026#34; assume_role_policy = data.aws_iam_policy_document.ecs_task_execution_assume_role.json } resource \u0026#34;aws_iam_policy\u0026#34; \u0026#34;ecs_task_execution_policy\u0026#34; { name = \u0026#34;ecs_task_execution_policy\u0026#34; policy = jsonencode({ \u0026#34;Version\u0026#34; : \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34; : [ { \u0026#34;Effect\u0026#34; : \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34; : [ \u0026#34;ecr:GetDownloadUrlForLayer\u0026#34;, \u0026#34;ecr:BatchCheckLayerAvailability\u0026#34;, \u0026#34;ecr:GetDownloadUrlForLayer\u0026#34;, \u0026#34;ecr:BatchGetImage\u0026#34;, \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34;, \u0026#34;ecr:GetAuthorizationToken\u0026#34; ], \u0026#34;Resource\u0026#34; : \u0026#34;*\u0026#34; } ] }) depends_on = [ aws_iam_role.ecs_task_execution_role ] } resource \u0026#34;aws_iam_role_policy_attachment\u0026#34; \u0026#34;ecs_task_execution_role_attach\u0026#34; { role = aws_iam_role.ecs_task_execution_role.name policy_arn = aws_iam_policy.ecs_task_execution_policy.arn depends_on = [ aws_iam_policy.ecs_task_execution_policy ] } ################################# # ECS Task Role ################################# data \u0026#34;aws_iam_policy_document\u0026#34; \u0026#34;ecs_task_assume_role\u0026#34; { statement { actions = [\u0026#34;sts:AssumeRole\u0026#34;] principals { type = \u0026#34;Service\u0026#34; identifiers = [\u0026#34;ecs-tasks.amazonaws.com\u0026#34;] } } } resource \u0026#34;aws_iam_role\u0026#34; \u0026#34;ecs_task_role\u0026#34; { name = \u0026#34;ecs_task_role\u0026#34; assume_role_policy = data.aws_iam_policy_document.ecs_task_assume_role.json } resource \u0026#34;aws_iam_policy\u0026#34; \u0026#34;ecs_task_policy\u0026#34; { name = \u0026#34;ecs_task_policy\u0026#34; depends_on = [ aws_iam_role.ecs_task_role, aws_s3_bucket.video ] policy = jsonencode({ \u0026#34;Version\u0026#34; : \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34; : [ { \u0026#34;Effect\u0026#34; : \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34; : [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34; : [ \u0026#34;arn:aws:s3:::${var.bucket_video_name}\u0026#34;, \u0026#34;arn:aws:s3:::${var.bucket_video_name}/*\u0026#34; ] }, { \u0026#34;Effect\u0026#34; : \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34; : [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34; : \u0026#34;*\u0026#34; } ] }) } resource \u0026#34;aws_iam_role_policy_attachment\u0026#34; \u0026#34;ecs_task_role_attach\u0026#34; { role = aws_iam_role.ecs_task_role.name policy_arn = aws_iam_policy.ecs_task_policy.arn depends_on = [ aws_iam_policy.ecs_task_policy ] } # add invoke lambda policy to the role resource \u0026#34;aws_iam_policy\u0026#34; \u0026#34;lambda_invoke_policy\u0026#34; { name = \u0026#34;lambda_invoke_policy\u0026#34; policy = jsonencode({ \u0026#34;Version\u0026#34; : \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34; : [ { \u0026#34;Effect\u0026#34; : \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34; : [ \u0026#34;lambda:InvokeFunction\u0026#34; ], \u0026#34;Resource\u0026#34; : \u0026#34;*\u0026#34; } ] }) depends_on = [ aws_iam_role.ecs_task_role ] } resource \u0026#34;aws_iam_role_policy_attachment\u0026#34; \u0026#34;lambda_invoke_role_attach\u0026#34; { role = aws_iam_role.ecs_task_role.name policy_arn = aws_iam_policy.lambda_invoke_policy.arn depends_on = [ aws_iam_policy.lambda_invoke_policy ] } 3. Create Lambda Function ################################# # AWS Lambda Function ################################# resource \u0026#34;aws_lambda_function\u0026#34; \u0026#34;processing_data\u0026#34; { function_name = \u0026#34;processing_data\u0026#34; role = aws_iam_role.lambda_role.arn handler = \u0026#34;lambda_function.lambda_handler\u0026#34; runtime = \u0026#34;python3.8\u0026#34; filename = \u0026#34;${path.root}/src/processing-data/lambda/lambda_function.zip\u0026#34; timeout = 60 memory_size = 128 environment { variables = { ECS_CLUSTER_NAME = aws_ecs_cluster.video_processing.name ECS_TASK_DEFINITION = aws_ecs_task_definition.video_processing.family SUBNET_ID = var.subnet_ids[0] CONTAINER_NAME = local.container_name SECURITY_GROUP_ID = var.security_group_id } } depends_on = [ aws_iam_role.lambda_role, aws_ecs_cluster.video_processing, aws_ecs_task_definition.video_processing ] } ################################# # Lambda Permission to Allow S3 to Invoke ################################# resource \u0026#34;aws_lambda_permission\u0026#34; \u0026#34;allow_s3_invocation\u0026#34; { statement_id = \u0026#34;AllowS3InvokeLambda\u0026#34; action = \u0026#34;lambda:InvokeFunction\u0026#34; function_name = aws_lambda_function.processing_data.function_name principal = \u0026#34;s3.amazonaws.com\u0026#34; source_arn = aws_s3_bucket.video.arn } output \u0026#34;lambda_processing_data_arn\u0026#34; { value = aws_lambda_function.processing_data.arn } 4. Create S3 Bucket Folders for Video and Processed Video ################################# # Video Bucket ################################# resource \u0026#34;aws_s3_bucket\u0026#34; \u0026#34;video\u0026#34; { bucket = var.bucket_video_name tags = var.common_tags } ################################# # Create folder in S3 bucket ################################# locals { folder_names = [\u0026#34;video\u0026#34;, \u0026#34;keyframes\u0026#34;, \u0026#34;embeddings\u0026#34;, \u0026#34;metadata\u0026#34;] } resource \u0026#34;aws_s3_bucket_object\u0026#34; \u0026#34;create_folders\u0026#34; { for_each = { for idx, folder_name in local.folder_names : idx =\u0026gt; folder_name } bucket = aws_s3_bucket.video.id key = \u0026#34;${each.value}/\u0026#34; } output \u0026#34;video_bucket_id\u0026#34; { value = aws_s3_bucket.video.id } output \u0026#34;video_bucket_arn\u0026#34; { value = aws_s3_bucket.video.arn } 5. Code for Lambda Function import json import boto3 import os ecs_client = boto3.client(\u0026#34;ecs\u0026#34;) s3_client = boto3.client(\u0026#34;s3\u0026#34;) CLUSTER_NAME = os.environ.get(\u0026#34;ECS_CLUSTER_NAME\u0026#34;) TASK_DEFINITION = os.environ.get(\u0026#34;ECS_TASK_DEFINITION\u0026#34;) SUBNET_ID = os.environ.get(\u0026#34;SUBNET_ID\u0026#34;) SECURITY_GROUP_ID = os.environ.get(\u0026#34;SECURITY_GROUP_ID\u0026#34;) CONTAINER_NAME = os.environ.get(\u0026#34;CONTAINER_NAME\u0026#34;) def lambda_handler(event, context): print(event) bucket = event[\u0026#34;Records\u0026#34;][0][\u0026#34;s3\u0026#34;][\u0026#34;bucket\u0026#34;][\u0026#34;name\u0026#34;] key = event[\u0026#34;Records\u0026#34;][0][\u0026#34;s3\u0026#34;][\u0026#34;object\u0026#34;][\u0026#34;key\u0026#34;] print(f\u0026#34;Bucket: {bucket}\u0026#34;) print(f\u0026#34;Key: {key}\u0026#34;) response = ecs_client.run_task( cluster=CLUSTER_NAME, taskDefinition=TASK_DEFINITION, launchType=\u0026#34;FARGATE\u0026#34;, networkConfiguration={ \u0026#34;awsvpcConfiguration\u0026#34;: { \u0026#34;subnets\u0026#34;: [SUBNET_ID], \u0026#34;securityGroups\u0026#34;: [SECURITY_GROUP_ID], \u0026#34;assignPublicIp\u0026#34;: \u0026#34;ENABLED\u0026#34;, } }, overrides={ \u0026#34;containerOverrides\u0026#34;: [ { \u0026#34;name\u0026#34;: CONTAINER_NAME, \u0026#34;environment\u0026#34;: [ {\u0026#34;name\u0026#34;: \u0026#34;S3_BUCKET\u0026#34;, \u0026#34;value\u0026#34;: bucket}, {\u0026#34;name\u0026#34;: \u0026#34;INPUT_VIDEO_KEY\u0026#34;, \u0026#34;value\u0026#34;: key}, {\u0026#34;name\u0026#34;: \u0026#34;OUTPUT_FOLDER_PREFIX\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;keyframes/\u0026#34;}, ], } ] }, ) print(\u0026#34;ECS task response: \u0026#34;) print(response) return {\u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: \u0026#34;ECS Task Invoked Successfully\u0026#34;} "
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/6-deploy-with-terraform/6.3-embedding/",
	"title": "Embedding",
	"tags": [],
	"description": "Learn how to build a Semantic Video Search Vector Database using AWS services such as SageMaker, S3, OpenSearch, ECS Fargate, and Lambda.",
	"content": "1. Create Role for Lambda and Sagemaker Processing Job ################################# # SageMaker processing role ################################# resource \u0026#34;aws_iam_role\u0026#34; \u0026#34;sagemaker_processing_role\u0026#34; { name = \u0026#34;sagemaker-processing-role\u0026#34; assume_role_policy = jsonencode({ Version = \u0026#34;2012-10-17\u0026#34;, Statement = [ { Effect = \u0026#34;Allow\u0026#34;, Principal = { Service = \u0026#34;sagemaker.amazonaws.com\u0026#34; }, Action = \u0026#34;sts:AssumeRole\u0026#34; } ] }) } resource \u0026#34;aws_iam_policy\u0026#34; \u0026#34;sagemaker_processing_policy\u0026#34; { name = \u0026#34;sagemaker-processing-policy\u0026#34; description = \u0026#34;Policy for SageMaker Processing to access S3, ECR, and logs\u0026#34; policy = jsonencode({ Version = \u0026#34;2012-10-17\u0026#34;, Statement = [ { Effect = \u0026#34;Allow\u0026#34;, Action = [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:ListBucket\u0026#34; ], Resource = [ # TODO: Replace with your bucket name \u0026#34;arn:aws:s3:::${var.bucket_id}\u0026#34;, \u0026#34;arn:aws:s3:::${var.bucket_id}/*\u0026#34; ] }, { Effect = \u0026#34;Allow\u0026#34;, Action = [ \u0026#34;ecr:GetDownloadUrlForLayer\u0026#34;, \u0026#34;ecr:BatchCheckLayerAvailability\u0026#34;, \u0026#34;ecr:GetDownloadUrlForLayer\u0026#34;, \u0026#34;ecr:BatchGetImage\u0026#34;, \u0026#34;ecr:ListImages\u0026#34;, \u0026#34;ecr:GetAuthorizationToken\u0026#34; ], Resource = [ \u0026#34;*\u0026#34; ] }, { Effect = \u0026#34;Allow\u0026#34;, Action = [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], Resource = \u0026#34;*\u0026#34; } ] }) } resource \u0026#34;aws_iam_role_policy_attachment\u0026#34; \u0026#34;sagemaker_processing_policy_attachment\u0026#34; { policy_arn = aws_iam_policy.sagemaker_processing_policy.arn role = aws_iam_role.sagemaker_processing_role.name } output \u0026#34;sagemaker_processing_role_arn\u0026#34; { value = aws_iam_role.sagemaker_processing_role.arn } ################################# # Role for lambda function ################################# resource \u0026#34;aws_iam_role\u0026#34; \u0026#34;lambda_role\u0026#34; { name = \u0026#34;lambda-sagemaker-role\u0026#34; assume_role_policy = jsonencode({ Version = \u0026#34;2012-10-17\u0026#34;, Statement = [ { Action = \u0026#34;sts:AssumeRole\u0026#34;, Effect = \u0026#34;Allow\u0026#34;, Principal = { Service = \u0026#34;lambda.amazonaws.com\u0026#34; } } ] }) } resource \u0026#34;aws_iam_policy\u0026#34; \u0026#34;lambda_policy\u0026#34; { name = \u0026#34;lambda-sagemaker-policy\u0026#34; description = \u0026#34;Policy for Lambda to invoke SageMaker and access S3\u0026#34; policy = jsonencode({ Version = \u0026#34;2012-10-17\u0026#34;, Statement = [ { Effect = \u0026#34;Allow\u0026#34;, Action = [ \u0026#34;sagemaker:CreateProcessingJob\u0026#34;, \u0026#34;sagemaker:DescribeProcessingJob\u0026#34;, \u0026#34;sagemaker:ListProcessingJobs\u0026#34; ], Resource = \u0026#34;*\u0026#34; }, { Effect = \u0026#34;Allow\u0026#34;, Action = [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:ListBucket\u0026#34; ], Resource = [ \u0026#34;arn:aws:s3:::${var.bucket_id}\u0026#34;, \u0026#34;arn:aws:s3:::${var.bucket_id}/*\u0026#34; ] } ] }) } resource \u0026#34;aws_iam_role_policy_attachment\u0026#34; \u0026#34;lambda_policy_attachment\u0026#34; { policy_arn = aws_iam_policy.lambda_policy.arn role = aws_iam_role.lambda_role.name } # add basic execution policy to the role resource \u0026#34;aws_iam_role_policy\u0026#34; \u0026#34;lambda_execution_policy\u0026#34; { name = \u0026#34;lambda-sagemaker-execution-policy-${var.bucket_id}\u0026#34; role = aws_iam_role.lambda_role.id policy = jsonencode({ Version = \u0026#34;2012-10-17\u0026#34;, Statement = [ { Effect = \u0026#34;Allow\u0026#34;, Action = [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], Resource = \u0026#34;*\u0026#34; } ] }) } ################################# # IAM Policy for Lambda to Pass SageMaker Role ################################# resource \u0026#34;aws_iam_policy\u0026#34; \u0026#34;pass_role_policy\u0026#34; { name = \u0026#34;lambda-pass-sagemaker-role-policy\u0026#34; policy = jsonencode({ Version = \u0026#34;2012-10-17\u0026#34;, Statement = [ { Effect = \u0026#34;Allow\u0026#34;, Action = \u0026#34;iam:PassRole\u0026#34;, Resource = aws_iam_role.sagemaker_processing_role.arn } ] }) } resource \u0026#34;aws_iam_role_policy_attachment\u0026#34; \u0026#34;lambda_pass_role_policy_attachment\u0026#34; { role = aws_iam_role.lambda_role.name policy_arn = aws_iam_policy.pass_role_policy.arn } 2. Create Lambda Function ################################# # AWS Lambda Function ################################# resource \u0026#34;aws_lambda_function\u0026#34; \u0026#34;processing_data\u0026#34; { function_name = \u0026#34;embedding_data\u0026#34; role = aws_iam_role.lambda_role.arn handler = \u0026#34;lambda_function.lambda_handler\u0026#34; runtime = \u0026#34;python3.8\u0026#34; filename = \u0026#34;${path.root}/src/embedding/lambda/lambda_function.zip\u0026#34; timeout = 60 memory_size = 128 environment { variables = { SAGEMAKER_ROLE_ARN = aws_iam_role.sagemaker_processing_role.arn S3_BUCKET_NAME = var.bucket_id S3_OUTPUT_PREFIX = \u0026#34;embeddings/\u0026#34; } } depends_on = [ aws_iam_role.lambda_role, ] } resource \u0026#34;aws_lambda_permission\u0026#34; \u0026#34;allow_ecs\u0026#34; { statement_id = \u0026#34;AllowECSTaskInvoke\u0026#34; action = \u0026#34;lambda:InvokeFunction\u0026#34; function_name = aws_lambda_function.processing_data.arn principal = \u0026#34;ecs.amazonaws.com\u0026#34; } 3. Create S3 code folder for SageMaker Processing Job resource \u0026#34;aws_s3_bucket_object\u0026#34; \u0026#34;script\u0026#34; { bucket = var.bucket_id key = \u0026#34;code/script.py\u0026#34; source = \u0026#34;${path.root}/src/embedding/sagemaker-processing/script.py\u0026#34; } resource \u0026#34;aws_s3_bucket_object\u0026#34; \u0026#34;requirements\u0026#34; { bucket = var.bucket_id key = \u0026#34;code/requirements.txt\u0026#34; source = \u0026#34;${path.root}/src/embedding/sagemaker-processing/requirements.txt\u0026#34; } 4. Code for Lambda Function Create a folder containing the lambda function code and requirements.txt file. script.py requirements.txt The script.py file contains the code for creating a SageMaker Processing Job. import json import boto3 import os import time sagemaker = boto3.client(\u0026#39;sagemaker\u0026#39;) role_arn = os.environ.get(\u0026#39;SAGEMAKER_ROLE_ARN\u0026#39;) output_prefix = os.environ.get(\u0026#39;S3_OUTPUT_PREFIX\u0026#39;) def lambda_handler(event, context): bucket_name = event[\u0026#39;bucket_name\u0026#39;] input_prefix = \u0026#34;keyframes/\u0026#34; + event[\u0026#39;video_name\u0026#39;] + \u0026#34;/\u0026#34; s3_outdir = input_prefix.split(\u0026#39;/\u0026#39;)[1] print(f\u0026#34;Bucket Name: {bucket_name}\u0026#34;) print(f\u0026#34;Input Prefix: {input_prefix}\u0026#34;) processing_job_name = f\u0026#34;processing-job-{int(time.time())}\u0026#34; print(f\u0026#34;Processing Job Name: {processing_job_name}\u0026#34;) response = sagemaker.create_processing_job( ProcessingJobName=processing_job_name, RoleArn=role_arn, AppSpecification={ \u0026#39;ImageUri\u0026#39;: \u0026#34;763104351884.dkr.ecr.ap-southeast-1.amazonaws.com/pytorch-training:1.9-cpu-py38\u0026#34;, \u0026#39;ContainerEntrypoint\u0026#39;: [\u0026#39;python3\u0026#39;, \u0026#39;/opt/ml/processing/code/script.py\u0026#39;] }, ProcessingInputs=[ { \u0026#39;InputName\u0026#39;: \u0026#39;input\u0026#39;, \u0026#39;S3Input\u0026#39;: { \u0026#39;S3Uri\u0026#39;: f\u0026#39;s3://{bucket_name}/{input_prefix}\u0026#39;, \u0026#39;LocalPath\u0026#39;: \u0026#39;/opt/ml/processing/input\u0026#39;, \u0026#39;S3DataType\u0026#39;: \u0026#39;S3Prefix\u0026#39;, \u0026#39;S3InputMode\u0026#39;: \u0026#39;File\u0026#39;, }, }, { \u0026#39;InputName\u0026#39;: \u0026#39;code\u0026#39;, \u0026#39;S3Input\u0026#39;: { \u0026#39;S3Uri\u0026#39;: f\u0026#39;s3://{bucket_name}/code/\u0026#39;, \u0026#39;LocalPath\u0026#39;: \u0026#39;/opt/ml/processing/code\u0026#39;, \u0026#39;S3DataType\u0026#39;: \u0026#39;S3Prefix\u0026#39;, \u0026#39;S3InputMode\u0026#39;: \u0026#39;File\u0026#39;, }, } ], ProcessingOutputConfig={ \u0026#39;Outputs\u0026#39;: [ { \u0026#39;OutputName\u0026#39;: \u0026#39;output\u0026#39;, \u0026#39;S3Output\u0026#39;: { \u0026#39;S3Uri\u0026#39;: f\u0026#39;s3://{bucket_name}/{output_prefix}\u0026#39;, \u0026#39;LocalPath\u0026#39;: \u0026#39;/opt/ml/processing/output\u0026#39;, \u0026#39;S3UploadMode\u0026#39;: \u0026#39;EndOfJob\u0026#39; }, }, ], }, ProcessingResources={ \u0026#39;ClusterConfig\u0026#39;: { \u0026#39;InstanceCount\u0026#39;: 1, \u0026#39;InstanceType\u0026#39;: \u0026#39;ml.m5.xlarge\u0026#39;, \u0026#39;VolumeSizeInGB\u0026#39;: 30, }, }, Environment={ \u0026#39;S3_OUTDIR\u0026#39;: s3_outdir } ) print(response) return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps({ \u0026#39;message\u0026#39;: \u0026#39;SageMaker Processing Job created successfully\u0026#39;, \u0026#39;jobName\u0026#39;: processing_job_name, \u0026#39;response\u0026#39;: response }) } if __name__ == \u0026#39;__main__\u0026#39;: lambda_handler({}, {}) 5. Code for SageMaker Processing Job import os import sys import subprocess subprocess.check_call( [ sys.executable, \u0026#34;-m\u0026#34;, \u0026#34;pip\u0026#34;, \u0026#34;install\u0026#34;, \u0026#34;-r\u0026#34;, \u0026#34;/opt/ml/processing/code/requirements.txt\u0026#34;, ] ) import torch from sentence_transformers import SentenceTransformer from PIL import Image import numpy def processor(input_dir, output_dir , folder): print(\u0026#34;Loading model.....\u0026#34;) model = SentenceTransformer(\u0026#34;clip-ViT-B-32\u0026#34;) print(\u0026#34;Model loaded\u0026#34;) device = \u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34; model = model.to(device) print(f\u0026#34;Using device: {device}\u0026#34;) image_paths = os.listdir(os.path.join(input_dir)) images = [] for image_path in image_paths: image = Image.open(os.path.join(input_dir, image_path)) images.append(image) embeddings = model.encode(images) numpy.save(os.path.join(output_dir, f\u0026#34;{folder}.npy\u0026#34;), embeddings) print(f\u0026#34;Embeddings for {folder} saved\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: input_dir = \u0026#34;/opt/ml/processing/input\u0026#34; output_dir = \u0026#34;/opt/ml/processing/output\u0026#34; # Local testing # input_dir = \u0026#34;./dataset/keyframes/L01_V001\u0026#34; # output_dir = \u0026#34;./dataset/output\u0026#34; s3_out_dir = os.environ.get(\u0026#39;S3_OUTDIR\u0026#39;) if s3_out_dir is None: raise ValueError(\u0026#34;S3_OUTDIR environment variable is not set\u0026#34;) print(\u0026#34;Starting processing.....\u0026#34;) processor(input_dir, output_dir , s3_out_dir) print(\u0026#34;Processing complete\u0026#34;) The requirements.txt file contains the required libraries for the processing job. sentence_transformers pillow "
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/6-deploy-with-terraform/6.4-vectordb/",
	"title": "Vector Database",
	"tags": [],
	"description": "Learn how to build a Semantic Video Search Vector Database using AWS services such as SageMaker, S3, OpenSearch, ECS Fargate, and Lambda.",
	"content": "1. Create Role for lambda index, lambda query ################################# # Lambda Query Role ################################# data \u0026#34;aws_caller_identity\u0026#34; \u0026#34;current\u0026#34; {} resource \u0026#34;aws_iam_role\u0026#34; \u0026#34;lambda_opensearch_sagemaker_role\u0026#34; { name = \u0026#34;LambdaOpenSearchSageMakerRoleQuery\u0026#34; assume_role_policy = jsonencode({ Version = \u0026#34;2012-10-17\u0026#34;, Statement = [ { Effect = \u0026#34;Allow\u0026#34;, Principal = { Service = \u0026#34;lambda.amazonaws.com\u0026#34; }, Action = \u0026#34;sts:AssumeRole\u0026#34; } ] }) } resource \u0026#34;aws_iam_policy\u0026#34; \u0026#34;opensearch_policy\u0026#34; { name = \u0026#34;OpenSearchAccessPolicy\u0026#34; description = \u0026#34;Allow Lambda to access OpenSearch domains\u0026#34; policy = jsonencode({ Version = \u0026#34;2012-10-17\u0026#34;, Statement = [ { Effect = \u0026#34;Allow\u0026#34;, Action = [ \u0026#34;es:ESHttpPost\u0026#34;, \u0026#34;es:ESHttpGet\u0026#34;, \u0026#34;es:ESHttpPut\u0026#34;, \u0026#34;es:ESHttpDelete\u0026#34; ], # Resource = \u0026#34;arn:aws:es:ap-southeast-1:${data.aws_caller_identity.current.account_id}:domain/*\u0026#34; # TODO Resource = \u0026#34;*\u0026#34; } ] }) } resource \u0026#34;aws_iam_policy\u0026#34; \u0026#34;sagemaker_policy\u0026#34; { name = \u0026#34;SageMakerInvokePolicy\u0026#34; description = \u0026#34;Allow Lambda to invoke SageMaker endpoint\u0026#34; policy = jsonencode({ Version = \u0026#34;2012-10-17\u0026#34;, Statement = [ { Effect = \u0026#34;Allow\u0026#34;, Action = [ \u0026#34;sagemaker:InvokeEndpoint\u0026#34; ], # Resource = \u0026#34;arn:aws:sagemaker:ap-southeast-1:${data.aws_caller_identity.current.account_id}:endpoint/*\u0026#34; # TODO Resource = \u0026#34;*\u0026#34; } ] }) } resource \u0026#34;aws_iam_policy\u0026#34; \u0026#34;cloudwatch_logs_policy\u0026#34; { name = \u0026#34;CloudWatchLogsPolicy\u0026#34; description = \u0026#34;Allow Lambda to write logs to CloudWatch\u0026#34; policy = jsonencode({ Version = \u0026#34;2012-10-17\u0026#34;, Statement = [ { Effect = \u0026#34;Allow\u0026#34;, Action = [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], Resource = \u0026#34;arn:aws:logs:ap-southeast-1:${data.aws_caller_identity.current.account_id}:*\u0026#34; } ] }) } resource \u0026#34;aws_iam_role_policy_attachment\u0026#34; \u0026#34;attach_opensearch_policy\u0026#34; { role = aws_iam_role.lambda_opensearch_sagemaker_role.name policy_arn = aws_iam_policy.opensearch_policy.arn } resource \u0026#34;aws_iam_role_policy_attachment\u0026#34; \u0026#34;attach_sagemaker_policy\u0026#34; { role = aws_iam_role.lambda_opensearch_sagemaker_role.name policy_arn = aws_iam_policy.sagemaker_policy.arn } resource \u0026#34;aws_iam_role_policy_attachment\u0026#34; \u0026#34;attach_cloudwatch_logs_policy\u0026#34; { role = aws_iam_role.lambda_opensearch_sagemaker_role.name policy_arn = aws_iam_policy.cloudwatch_logs_policy.arn } ################################# # Lambda Index Role ################################# resource \u0026#34;aws_iam_role\u0026#34; \u0026#34;lambda_opensearch_sagemaker_role_index\u0026#34; { name = \u0026#34;LambdaOpenSearchSageMakerRoleQueryIndex\u0026#34; assume_role_policy = jsonencode({ Version = \u0026#34;2012-10-17\u0026#34; Statement = [ { Action = \u0026#34;sts:AssumeRole\u0026#34; Effect = \u0026#34;Allow\u0026#34; Principal = { Service = \u0026#34;lambda.amazonaws.com\u0026#34; } } ] }) } resource \u0026#34;aws_iam_role_policy_attachment\u0026#34; \u0026#34;lambda_basic_execution_policy\u0026#34; { role = aws_iam_role.lambda_opensearch_sagemaker_role_index.name policy_arn = \u0026#34;arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole\u0026#34; } resource \u0026#34;aws_iam_role_policy_attachment\u0026#34; \u0026#34;s3_read_only_policy\u0026#34; { role = aws_iam_role.lambda_opensearch_sagemaker_role_index.name policy_arn = \u0026#34;arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\u0026#34; } resource \u0026#34;aws_iam_role_policy_attachment\u0026#34; \u0026#34;opensearch_access_policy\u0026#34; { role = aws_iam_role.lambda_opensearch_sagemaker_role_index.name policy_arn = \u0026#34;arn:aws:iam::aws:policy/AmazonOpenSearchServiceFullAccess\u0026#34; # Thay thế bằng chính sách tùy chỉnh nếu cần } 2. Create Lambda Function for Indexing and Querying ################################# # AWS Lambda Function Query ################################# resource \u0026#34;aws_lambda_function\u0026#34; \u0026#34;query\u0026#34; { function_name = \u0026#34;query-vectordb\u0026#34; role = aws_iam_role.lambda_opensearch_sagemaker_role.arn handler = \u0026#34;lambda_function.lambda_handler\u0026#34; runtime = \u0026#34;python3.8\u0026#34; filename = \u0026#34;${path.root}/src/vectordb/lambda-query/lambda_function.zip\u0026#34; timeout = 60 memory_size = 128 environment { variables = { SAGEMAKER_ENDPOINT_NAME = var.sagemaker_endpoint_name } } depends_on = [ aws_iam_role.lambda_opensearch_sagemaker_role, ] } output \u0026#34;lambda_function_name\u0026#34; { value = aws_lambda_function.query.function_name } output \u0026#34;lambda_invoke_arn\u0026#34; { value = aws_lambda_function.query.invoke_arn } ################################# # AWS Lambda Function Indexing ################################# resource \u0026#34;aws_lambda_function\u0026#34; \u0026#34;index\u0026#34; { function_name = \u0026#34;index-vectordb\u0026#34; role = aws_iam_role.lambda_opensearch_sagemaker_role_index.arn handler = \u0026#34;lambda_function.lambda_handler\u0026#34; runtime = \u0026#34;python3.8\u0026#34; filename = \u0026#34;${path.root}/src/vectordb/lambda-index/lambda_function.zip\u0026#34; timeout = 300 memory_size = 1024 layers = [ aws_lambda_layer_version.opensearch_numpy_layer.arn, # aws_lambda_layer_version.aws4auth_layer_zip.arn ] environment { variables = { OPENSEARCH_ENDPOINT = var.opensearch_domain_endpoint INDEX_NAME = var.index_name USERNAME = var.username PASSWORD = var.password } } } resource \u0026#34;aws_s3_bucket_object\u0026#34; \u0026#34;opensearch_numpy_layer_zip\u0026#34; { bucket = var.bucket_name key = \u0026#34;lambda-layer/lamda_layer.zip\u0026#34; source = \u0026#34;${path.root}/src/vectordb/lambda-index/lambda_layer.zip\u0026#34; } resource \u0026#34;aws_lambda_layer_version\u0026#34; \u0026#34;opensearch_numpy_layer\u0026#34; { layer_name = \u0026#34;opensearch-numpy-layer\u0026#34; s3_bucket = var.bucket_name s3_key = aws_s3_bucket_object.opensearch_numpy_layer_zip.key compatible_runtimes = [\u0026#34;python3.8\u0026#34;] description = \u0026#34;Lambda layer with numpy and opensearch-py\u0026#34; } Create S3 notifications ################################# # Lambda Permission to Allow S3 to Invoke ################################# resource \u0026#34;aws_lambda_permission\u0026#34; \u0026#34;allow_s3_invocation_embeddings\u0026#34; { statement_id = \u0026#34;AllowS3InvokeLambda\u0026#34; action = \u0026#34;lambda:InvokeFunction\u0026#34; function_name = aws_lambda_function.index.function_name principal = \u0026#34;s3.amazonaws.com\u0026#34; source_arn = var.bucket_arn } ################################# # Embeddings Bucket Notification ################################# resource \u0026#34;aws_s3_bucket_notification\u0026#34; \u0026#34;embeddings_bucket_notification\u0026#34; { bucket = var.bucket_name lambda_function { lambda_function_arn = aws_lambda_function.index.arn events = [\u0026#34;s3:ObjectCreated:*\u0026#34;] filter_suffix = \u0026#34;.npy\u0026#34; filter_prefix = \u0026#34;embeddings/\u0026#34; } lambda_function { lambda_function_arn = var.lambda_processing_data_arn events = [\u0026#34;s3:ObjectCreated:*\u0026#34;] filter_suffix = \u0026#34;.mp4\u0026#34; filter_prefix = \u0026#34;video/\u0026#34; } } Code for Lambda Function Code for Lambda Index import json import boto3 import os import numpy from opensearchpy import OpenSearch, RequestsHttpConnection , helpers OPENSEARCH_ENDPOINT = os.environ.get(\u0026#34;OPENSEARCH_ENDPOINT\u0026#34;) OPENSEARCH_INDEX = os.environ.get(\u0026#34;INDEX_NAME\u0026#34;) USERNAME = os.environ.get(\u0026#34;USERNAME\u0026#34;) PASSWORD = os.environ.get(\u0026#34;PASSWORD\u0026#34;) s3_client = boto3.client(\u0026#34;s3\u0026#34;) client = OpenSearch( hosts=[OPENSEARCH_ENDPOINT], http_auth=(USERNAME, PASSWORD), use_ssl=True, verify_certs=True, connection_class=RequestsHttpConnection, timeout=120, max_retries=5, retry_on_timeout=True, ) def create_index(self): index_body = { \u0026#34;settings\u0026#34;: {\u0026#34;index\u0026#34;: {\u0026#34;knn\u0026#34;: True}}, \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;image_embedding\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;knn_vector\u0026#34;, \u0026#34;dimension\u0026#34;: 512, \u0026#34;method\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hnsw\u0026#34;, \u0026#34;engine\u0026#34;: \u0026#34;faiss\u0026#34;, \u0026#34;space_type\u0026#34;: \u0026#34;l2\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;ef_construction\u0026#34;: 256, \u0026#34;m\u0026#34;: 48, }, }, }, \u0026#34;video\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;}, \u0026#34;image\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34;}, } }, } # Tạo index response = self.client.indices.create(index=self.index_name, body=index_body) print(f\u0026#34;Index created: {response}\u0026#34;) def format_video_name(video_name): return video_name.split(\u0026#34;/\u0026#34;)[-1].split(\u0026#34;.\u0026#34;)[0] def format_image_name(image_name): # 2 =\u0026gt; 002.jpg return image_name.split(\u0026#34;/\u0026#34;)[-1].split(\u0026#34;.\u0026#34;)[0].zfill(3) def lambda_handler(event, context): print(event) bucket = event[\u0026#34;Records\u0026#34;][0][\u0026#34;s3\u0026#34;][\u0026#34;bucket\u0026#34;][\u0026#34;name\u0026#34;] key = event[\u0026#34;Records\u0026#34;][0][\u0026#34;s3\u0026#34;][\u0026#34;object\u0026#34;][\u0026#34;key\u0026#34;] # bucket = \u0026#39;bucket-video-tftftftfttftf\u0026#39; # key = \u0026#39;embeddings/L01_V001.npy\u0026#39; print(f\u0026#34;Bucket: {bucket}\u0026#34;) print(f\u0026#34;Key: {key}\u0026#34;) video_name = format_video_name(key) # Create index if not exists if not client.indices.exists(index=OPENSEARCH_INDEX): create_index(client) embeddings = s3_client.get_object(Bucket=bucket, Key=key)[\u0026#34;Body\u0026#34;].read() embeddings = numpy.load(embeddings).tolist() print(\u0026#34;Embeddings: \u0026#34;, embeddings[0]) # Create mapping of embeddings to video names docs = [] for i, embedding in enumerate(embeddings): doc = { \u0026#34;_op_type\u0026#34;: \u0026#34;index\u0026#34;, \u0026#34;_index\u0026#34;: OPENSEARCH_INDEX, \u0026#34;_id\u0026#34;: i + 1, \u0026#34;_source\u0026#34;: { \u0026#34;image_embedding\u0026#34;: embedding, \u0026#34;image\u0026#34;: format_image_name(i), \u0026#34;video\u0026#34;: video_name, }, } docs.append(doc) print(\u0026#34;Creating docs: OK\u0026#34;) response = helpers.bulk(client, docs) print(\u0026#34;Response: \u0026#34;, response) return { \u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: json.dumps(\u0026#34;Indexing complete!\u0026#34;), } Code for Lambda Query ################################# # AWS Lambda Function Query ################################# resource \u0026#34;aws_lambda_function\u0026#34; \u0026#34;query\u0026#34; { function_name = \u0026#34;query-vectordb\u0026#34; role = aws_iam_role.lambda_opensearch_sagemaker_role.arn handler = \u0026#34;lambda_function.lambda_handler\u0026#34; runtime = \u0026#34;python3.8\u0026#34; filename = \u0026#34;${path.root}/src/vectordb/lambda-query/lambda_function.zip\u0026#34; timeout = 60 memory_size = 128 environment { variables = { SAGEMAKER_ENDPOINT_NAME = var.sagemaker_endpoint_name OPENSEARCH_ENDPOINT = var.opensearch_domain_endpoint INDEX_NAME = var.index_name USERNAME = var.username PASSWORD = var.password } } layers = [ aws_lambda_layer_version.opensearch_numpy_layer.arn, ] depends_on = [ aws_iam_role.lambda_opensearch_sagemaker_role, ] } output \u0026#34;lambda_function_name\u0026#34; { value = aws_lambda_function.query.function_name } output \u0026#34;lambda_invoke_arn\u0026#34; { value = aws_lambda_function.query.invoke_arn } ################################# # AWS Lambda Function Indexing ################################# resource \u0026#34;aws_lambda_function\u0026#34; \u0026#34;index\u0026#34; { function_name = \u0026#34;index-vectordb\u0026#34; role = aws_iam_role.lambda_opensearch_sagemaker_role_index.arn handler = \u0026#34;lambda_function.lambda_handler\u0026#34; runtime = \u0026#34;python3.8\u0026#34; filename = \u0026#34;${path.root}/src/vectordb/lambda-index/lambda_function.zip\u0026#34; timeout = 300 memory_size = 1024 layers = [ aws_lambda_layer_version.opensearch_numpy_layer.arn, ] environment { variables = { OPENSEARCH_ENDPOINT = var.opensearch_domain_endpoint INDEX_NAME = var.index_name USERNAME = var.username PASSWORD = var.password } } } resource \u0026#34;aws_s3_bucket_object\u0026#34; \u0026#34;opensearch_numpy_layer_zip\u0026#34; { bucket = var.bucket_name key = \u0026#34;lambda-layer/lamda_layer.zip\u0026#34; source = \u0026#34;${path.root}/src/vectordb/lambda-index/lambda_layer.zip\u0026#34; } resource \u0026#34;aws_lambda_layer_version\u0026#34; \u0026#34;opensearch_numpy_layer\u0026#34; { layer_name = \u0026#34;opensearch-numpy-layer\u0026#34; s3_bucket = var.bucket_name s3_key = aws_s3_bucket_object.opensearch_numpy_layer_zip.key compatible_runtimes = [\u0026#34;python3.8\u0026#34;] description = \u0026#34;Lambda layer with numpy and opensearch-py\u0026#34; } Create Lambda Layers cd src/vectordb/lambda-index pip install -r requirements.txt -t python zip -r lambda_layer.zip python "
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/6-deploy-with-terraform/6.5-cms/",
	"title": "CMS",
	"tags": [],
	"description": "Learn how to build a Semantic Video Search Vector Database using AWS services such as SageMaker, S3, OpenSearch, ECS Fargate, and Lambda.",
	"content": "1. Create Cognito User Pool and Client locals { user_pool_name = \u0026#34;semantic-user-pool\u0026#34; } resource \u0026#34;aws_cognito_user_pool\u0026#34; \u0026#34;user_pool\u0026#34; { name = local.user_pool_name } resource \u0026#34;aws_cognito_user_pool_client\u0026#34; \u0026#34;user_pool_client\u0026#34; { name = \u0026#34;semantic-client\u0026#34; user_pool_id = aws_cognito_user_pool.user_pool.id generate_secret = false depends_on = [ aws_cognito_user_pool.user_pool ] explicit_auth_flows = [ \u0026#34;ADMIN_NO_SRP_AUTH\u0026#34;, \u0026#34;USER_PASSWORD_AUTH\u0026#34; ] } resource \u0026#34;aws_cognito_user_pool_domain\u0026#34; \u0026#34;user_pool_domain\u0026#34; { domain = \u0026#34;semantic-domain\u0026#34; user_pool_id = aws_cognito_user_pool.user_pool.id depends_on = [ aws_cognito_user_pool.user_pool ] } output \u0026#34;user_pool_id\u0026#34; { value = aws_cognito_user_pool.user_pool.id } output \u0026#34;user_pool_client_id\u0026#34; { value = aws_cognito_user_pool_client.user_pool_client.id } 2. Create API Gateway locals { api_gateway_name = \u0026#34;semantic-api\u0026#34; route_path = \u0026#34;predict\u0026#34; } ################################# # API Gateway ################################# resource \u0026#34;aws_api_gateway_rest_api\u0026#34; \u0026#34;my_api\u0026#34; { name = local.api_gateway_name description = \u0026#34;API Gateway for my Lambda function\u0026#34; } resource \u0026#34;aws_api_gateway_resource\u0026#34; \u0026#34;images_resource\u0026#34; { rest_api_id = aws_api_gateway_rest_api.my_api.id parent_id = aws_api_gateway_rest_api.my_api.root_resource_id path_part = local.route_path depends_on = [ aws_api_gateway_rest_api.my_api ] } # Authorizer resource \u0026#34;aws_api_gateway_authorizer\u0026#34; \u0026#34;cognito_authorizer\u0026#34; { name = \u0026#34;cognito-authorizer\u0026#34; rest_api_id = aws_api_gateway_rest_api.my_api.id provider_arns = [aws_cognito_user_pool.user_pool.arn] identity_source = \u0026#34;method.request.header.Authorization\u0026#34; type = \u0026#34;COGNITO_USER_POOLS\u0026#34; depends_on = [ aws_api_gateway_rest_api.my_api, aws_cognito_user_pool.user_pool ] } resource \u0026#34;aws_api_gateway_method\u0026#34; \u0026#34;images_method\u0026#34; { rest_api_id = aws_api_gateway_rest_api.my_api.id resource_id = aws_api_gateway_resource.images_resource.id http_method = \u0026#34;POST\u0026#34; authorization = \u0026#34;COGNITO_USER_POOLS\u0026#34; authorizer_id = aws_api_gateway_authorizer.cognito_authorizer.id request_parameters = { \u0026#34;method.request.path.proxy\u0026#34; = true } depends_on = [ aws_api_gateway_resource.images_resource ] } resource \u0026#34;aws_api_gateway_integration\u0026#34; \u0026#34;lambda_integration\u0026#34; { rest_api_id = aws_api_gateway_rest_api.my_api.id resource_id = aws_api_gateway_resource.images_resource.id http_method = aws_api_gateway_method.images_method.http_method integration_http_method = \u0026#34;POST\u0026#34; type = \u0026#34;AWS_PROXY\u0026#34; uri = var.lambda_invoke_arn depends_on = [ aws_api_gateway_method.images_method, ] } resource \u0026#34;aws_lambda_permission\u0026#34; \u0026#34;apigw_lambda\u0026#34; { statement_id = \u0026#34;AllowAPIGatewayInvoke\u0026#34; action = \u0026#34;lambda:InvokeFunction\u0026#34; function_name = var.function_name principal = \u0026#34;apigateway.amazonaws.com\u0026#34; source_arn = \u0026#34;${aws_api_gateway_rest_api.my_api.execution_arn}/*/*\u0026#34; depends_on = [ aws_api_gateway_integration.lambda_integration, ] } # Method response resource \u0026#34;aws_api_gateway_method_response\u0026#34; \u0026#34;get_response\u0026#34; { rest_api_id = aws_api_gateway_rest_api.my_api.id resource_id = aws_api_gateway_resource.images_resource.id http_method = aws_api_gateway_method.images_method.http_method status_code = \u0026#34;200\u0026#34; } # Integration response resource \u0026#34;aws_api_gateway_integration_response\u0026#34; \u0026#34;lambda_integration_response\u0026#34; { rest_api_id = aws_api_gateway_rest_api.my_api.id resource_id = aws_api_gateway_resource.images_resource.id http_method = aws_api_gateway_method.images_method.http_method status_code = aws_api_gateway_method_response.get_response.status_code depends_on = [ aws_api_gateway_integration.lambda_integration ] } # Deploy all resources resource \u0026#34;aws_api_gateway_deployment\u0026#34; \u0026#34;mydeployment\u0026#34; { depends_on = [ aws_api_gateway_resource.images_resource, aws_api_gateway_integration.lambda_integration, aws_api_gateway_integration_response.lambda_integration_response, aws_api_gateway_method.images_method, aws_api_gateway_method_response.get_response ] rest_api_id = aws_api_gateway_rest_api.my_api.id stage_name = \u0026#34;dev\u0026#34; } "
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/7-clean-up/",
	"title": "Clean Up",
	"tags": [],
	"description": "Learn how to build a Semantic Video Search Vector Database using AWS services such as SageMaker, S3, OpenSearch, ECS Fargate, and Lambda.",
	"content": "1. Delete Resources Managed by Terraform terraform destroy 2. Delete OpenSearch Domain Navigate to the OpenSearch Service console at OpenSearch Service. Select the domain with the name semantic-video-search. Click on the Delete button. 3. Delete S3 Bucket Navigate to the S3 console at S3 Console. Select the bucket with the name ai-challenge-2024. Click on the Delete button. 4. Delete ECR Repository Navigate to the Elastic Container Registry console at ECR Console. Select the repository with the name ai-challenge-2024. Click on the Delete button. 5. Delete SageMaker Endpoint Navigate to the SageMaker console at SageMaker Console. Select the endpoint with the name clip-model-{time}. Click on the Delete button. "
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]