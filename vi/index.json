[
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/vi/",
	"title": "Giới thiệu chuỗi 100 ngày AWS Hand On Labs",
	"tags": [],
	"description": "Khám phá Introduce Series 100 AWS Hands-On Labs, được thiết kế cho người mới bắt đầu tìm hiểu AWS với các bài tập thực hành từng bước",
	"content": "Giới thiệu chuỗi 100 ngày AWS Hand On Labs Chào mừng bạn đến với loạt bài \u0026ldquo;100 ngày trên đám mây\u0026rdquo;—một hành trình chuyên sâu kéo dài 100 ngày được thiết kế để chuyển đổi kỹ năng điện toán đám mây của bạn từ cơ bản đến nâng cao. Cho dù bạn là chuyên gia CNTT, nhà phát triển hay người mong muốn tìm hiểu thế giới công nghệ đám mây, loạt bài này được thiết kế để trang bị cho bạn kiến ​​thức và kỹ năng thực tế cần thiết để vượt trội trong bối cảnh đám mây không ngừng phát triển.\nChương trình \u0026ldquo;100 Days Cloud\u0026rdquo; là gì? Chuỗi \u0026ldquo;100 Days Cloud\u0026rdquo; là một chương trình giáo dục có cấu trúc nhằm cung cấp sự hiểu biết toàn diện về điện toán đám mây trong khoảng thời gian 100 ngày. Mỗi ngày, bạn sẽ tham gia vào các khái niệm mới, bài tập thực hành và các tình huống thực tế để nâng cao kiến ​​thức chuyên môn của mình.\nNhững điểm nổi bật của chương trình: Bài học hàng ngày: Nhận một bài học mới mỗi ngày, bao gồm các chủ đề từ cơ bản đến nâng cao về điện toán đám mây.\nDự án thực hành: Áp dụng những gì bạn học được thông qua các bài tập thực hành và các dự án thực tế.\nHỗ trợ cộng đồng: Tham gia cộng đồng người học để thảo luận, hỗ trợ và có cơ hội kết nối.\nTại sao bạn nên tham gia chuỗi chương trình \u0026ldquo;100 Days Cloud\u0026rdquo; 1. Lộ trình Loạt bài này cung cấp lộ trình học được tổ chức tốt, đảm bảo bạn sẽ bao quát được mọi khía cạnh quan trọng của điện toán đám mây, bao gồm:\nCơ bản về đám mây: Hiểu các khái niệm cốt lõi như mô hình đám mây (IaaS, PaaS, SaaS), mô hình triển khai và các dịch vụ đám mây thiết yếu.\nCác nhà cung cấp đám mây lớn: Tìm hiểu sâu hơn về các nền tảng hàng đầu như AWS, Azure và Google Cloud, đồng thời tìm hiểu cách tận dụng hiệu quả các dịch vụ của họ.\nBảo mật đám mây: Khám phá các phương pháp hay nhất để bảo mật môi trường đám mây và quản lý quyền riêng tư dữ liệu.\nDevOps và Tự động hóa: Đi sâu vào các phương pháp DevOps và các công cụ tự động hóa đám mây để hợp lý hóa quá trình phát triển và vận hành.\n2. Kinh nghiệm thực tế Loạt bài tập trung vào kinh nghiệm thực tế, cho phép bạn:\nLàm việc trên các dự án thực tế: Triển khai những gì bạn đã học thông qua các dự án thực hành và nghiên cứu tình huống. Xây dựng danh mục đầu tư: Thể hiện các kỹ năng của bạn với danh mục các dự án đã hoàn thành. 3. Hướng dẫn Học hỏi từ những người giàu kinh nghiệm, những người sẽ cung cấp:\nHướng dẫn chi tiết: Hướng dẫn từng bước và video hướng dẫn. Phiên hỏi đáp: Phiên trực tiếp để trả lời các câu hỏi của bạn và làm rõ những thắc mắc. 4. Cơ hội giao lưu Kết nối với những người học trong lĩnh vực điện toán đám mây:\nDiễn đàn thảo luận: Tham gia thảo luận, chia sẻ hiểu biết và nhận phản hồi. Cách bắt đầu Tham gia chuỗi \u0026ldquo;100 Days Cloud\u0026rdquo; rất đơn giản:\nĐặt mục tiêu: Xác định mục tiêu học tập và theo dõi tiến trình của bạn trong suốt chuỗi. Tham gia tích cực: Tham gia các bài tập, đóng góp vào các cuộc thảo luận và tận dụng cộng đồng để được hỗ trợ. Nội dung 1. Tại sao bạn nên học aws? 2. Thực hành với AWS lambda serverless 3. Thực hành xây dựng ứng dụng Zero Downtime trên AWS 4. Thực hành xây dựng ứng dụng âm nhạc serverless trên AWS Kết luận Chuỗi khóa học \u0026ldquo;100 Days Cloud\u0026rdquo; không chỉ là một chương trình học; mà còn là cam kết nâng cao kỹ năng điện toán đám mây của bạn và định vị bản thân là một chuyên gia thành thạo trong một lĩnh vực đang phát triển nhanh chóng. Đừng bỏ lỡ cơ hội này để nâng cao kiến ​​thức và triển vọng nghề nghiệp của bạn.\nHãy tham gia cùng chúng tôi ngay hôm nay và bắt đầu hành trình làm chủ đám mây của bạn với chuỗi \u0026ldquo;100 Days Cloud\u0026rdquo;!\nTừ khóa: aws thực hành cho người mới bắt đầu, aws thực hành phòng thí nghiệm pdf, aws thực hành dự án, aws thực hành đào tạo, aws thực hành, aws thực hành bài tập, aws thực hành hội thảo, aws thực hành khóa học, aws thực hành phòng thí nghiệm, aws 100 ngày, aws là gì?\n"
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/vi/1-introduction/",
	"title": "Workshop Hệ Thống Cơ Sở Dữ Liệu Tìm Kiếm Video Ngữ Nghĩa",
	"tags": [],
	"description": "Tìm hiểu cách xây dựng hệ thống cơ sở dữ liệu tìm kiếm video ngữ nghĩa sử dụng các dịch vụ AWS như SageMaker, S3, OpenSearch, ECS Fargate, và Lambda.",
	"content": "Chào mừng bạn đến với workshop \u0026ldquo;Hệ Thống Cơ Sở Dữ Liệu Tìm Kiếm Video Ngữ Nghĩa\u0026rdquo;! Trong workshop này, chúng tôi sẽ hướng dẫn bạn xây dựng một hệ thống tìm kiếm video toàn diện sử dụng các dịch vụ AWS. Bạn sẽ học cách nhập, xử lý và tìm kiếm dữ liệu video một cách hiệu quả bằng các công cụ AWS.\nModules Cài Đặt S3 Để Lưu Trữ Video\nMục Tiêu: Học cách sử dụng Amazon S3 để lưu trữ và quản lý dữ liệu video. Mô Tả: Khám phá cách thiết lập và cấu hình các bucket S3 để lưu trữ video, quản lý dữ liệu hiệu quả và đảm bảo khả năng truy cập để xử lý. Nhập Dữ Liệu Với ECS Fargate\nMục Tiêu: Hiểu cách sử dụng ECS Fargate để nhập và xử lý dữ liệu. Mô Tả: Học cách triển khai và quản lý các ứng dụng containerized bằng ECS Fargate để xử lý dữ liệu video và tiền xử lý. Trích Xuất Tính Năng Sử Dụng SageMaker\nMục Tiêu: Trích xuất các tính năng quan trọng từ dữ liệu video bằng SageMaker. Mô Tả: Thực hiện các thuật toán trích xuất tính năng để chuyển đổi dữ liệu video thành các vector có thể tìm kiếm. Học cách sử dụng các công cụ của SageMaker để xử lý và phân tích nội dung video. Triển Khai OpenSearch Để Tạo Cơ Sở Dữ Liệu Vector\nMục Tiêu: Cài đặt và sử dụng OpenSearch để lưu trữ và truy vấn các vector video. Mô Tả: Cấu hình OpenSearch như một cơ sở dữ liệu vector để hỗ trợ chức năng tìm kiếm nhanh chóng và hiệu quả. Học cách lập chỉ mục và truy xuất các tính năng video để tìm kiếm ngữ nghĩa. Tích Hợp Lambda Để Điều Phối\nMục Tiêu: Sử dụng AWS Lambda để điều phối và tự động hóa quy trình làm việc. Mô Tả: Khám phá cách tích hợp các hàm Lambda để tự động hóa quy trình xử lý, quản lý luồng dữ liệu giữa các dịch vụ và kích hoạt các hành động dựa trên sự kiện. Tổng quan 1.Amazon SageMaker: là dịch vụ được quản lý hoàn toàn cung cấp các công cụ để xây dựng, huấn luyện và triển khai các mô hình học máy. Nó cung cấp các notebook Jupyter tích hợp, tự động điều chỉnh mô hình, và các thuật toán tích hợp, giúp đơn giản hóa việc phát triển và quản lý quy trình học máy.\n2.Amazon Simple Storage Service (S3): là dịch vụ lưu trữ đối tượng mở rộng giúp cung cấp độ khả dụng và độ bền cao cho dữ liệu của bạn. Nó thường được sử dụng để lưu trữ lượng lớn dữ liệu, bao gồm các tệp video, với mô hình giá theo mức sử dụng.\n3.Amazon Elastic Container Service (ECS) Fargate: cho phép bạn chạy các container mà không cần quản lý cơ sở hạ tầng dưới đây. Fargate tự động cấp phát và mở rộng các ứng dụng containerized, giúp đơn giản hóa việc nhập và xử lý dữ liệu.\n4.OpenSearch: là công cụ tìm kiếm và phân tích giúp bạn lưu trữ, tìm kiếm và phân tích khối lượng lớn dữ liệu một cách nhanh chóng. Nó cung cấp các khả năng tìm kiếm mạnh mẽ và lý tưởng để triển khai cơ sở dữ liệu vector cho tìm kiếm ngữ nghĩa.\n5.AWS Lambda: là dịch vụ tính toán không máy chủ cho phép bạn chạy mã theo phản hồi sự kiện mà không cần cấp phát hoặc quản lý máy chủ. Các hàm Lambda có thể được sử dụng để tự động hóa quy trình làm việc, xử lý dữ liệu và tích hợp các dịch vụ AWS khác.\nConclusion By completing this workshop, you will gain hands-on experience with AWS services to build a scalable and efficient Semantic Video Search Vector Database. You will be equipped with the skills to manage video data, extract features, and implement a powerful search system using AWS technologies.\nJoin us and start building your own video search solution today!\nKeywords: AWS SageMaker, Amazon S3, Amazon ECS Fargate, OpenSearch, AWS Lambda\n"
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/vi/2-settup-s3/",
	"title": "Setting Up S3 for Video Storage",
	"tags": [],
	"description": "Modules",
	"content": "1.1 Tạo một S3 Bucket Điều hướng đến S3 bằng cách nhấp vào menu Dịch vụ (Services), trong phần Lưu trữ (Storage). Nhấp vào nút Tạo Bucket (Create bucket). Trong phần Cấu hình chung (General Configuration): Tên Bucket (Bucket name): Nhập ai-challenge-2024. Lưu ý: Tên S3 Bucket là duy nhất toàn cầu, hãy chọn một tên có sẵn. Khu vực (Region): Chọn US East (N. Virginia) us-east-1 (cùng khu vực với Kinesis data stream). Trong phần Mã hóa mặc định (Default encryption): Loại khóa mã hóa (Encryption key type): Để mặc định là Amazon S3 key (SSE-S3). Khóa Bucket (Bucket key): Chọn Bật (Enable). Nhấp vào nút Tạo Bucket (Create bucket). 1.2 Tạo thư mục trong S3 Bucket Nhấp vào tên bucket ai-challenge-2024. Nhấp vào nút Tạo thư mục (Create folder). Nhập tên thư mục là keyframes và nhấp vào Lưu (Save). Lặp lại các bước trên để tạo thư mục khác với tên video. "
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/vi/3-ingrest-data/3.1-create-vpc/",
	"title": "Create VPC",
	"tags": [],
	"description": "Modules",
	"content": "Tạo một VPC Điều hướng đến VPC bằng cách nhấp vào menu Dịch vụ (Services), trong phần Mạng và Phân phối Nội dung (Networking \u0026amp; Content Delivery). Nhấp vào VPC của bạn (Your VPCs) trong bảng điều hướng bên trái. Nhấp vào nút Tạo VPC (Create VPC). Trong trang Cài đặt VPC (VPC settings): Tài nguyên để tạo (Resources to create): Chọn VPC và nhiều hơn nữa (VPC and more). Thẻ tên (Name tag): Nhập ai-challenge-vpc. Khối CIDR IPv4 (IPv4 CIDR block): Nhập 10.0.0.0/16. Nhấp vào nút Tạo VPC (Create VPC). Với tùy chọn VPC và nhiều hơn nữa (VPC and more), bạn sẽ nhận được một mẫu hoàn chỉnh bao gồm subnet, bảng định tuyến (route table), và VPCE (S3 gateway endpoint), giúp thực hiện các tác vụ ECS và các job của SageMaker.\n"
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/vi/3-ingrest-data/",
	"title": "Ingesting Data with ECS Fargate",
	"tags": [],
	"description": "Modules",
	"content": "Tổng Quan Trong mô-đun này, bạn sẽ học cách nhập dữ liệu vào hệ thống tìm kiếm video của bạn bằng cách sử dụng ECS Fargate. Chúng tôi sẽ hướng dẫn bạn qua quy trình tạo định nghĩa tác vụ, cấu hình cài đặt mạng và chạy tác vụ để nhập dữ liệu từ S3 vào cluster ECS Fargate của bạn.\nNội Dung Create VPC Set Up ECR Repository Create ECS Task Definition Run ECS Task "
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/vi/3-ingrest-data/3.2-erc-repo/",
	"title": "Set Up ECR Repository",
	"tags": [],
	"description": "Modules",
	"content": "Tạo ECR Image 1 Tạo một ECR Repository Điều hướng đến ECR bằng cách nhấp vào menu Dịch vụ (Services), trong phần Container. Nhấp vào nút Tạo repository (Create repository). Trong phần Cài đặt chung (General settings): Tên repository (Repository name): Nhập ai-challenge-2024. Tính không đổi của tag ảnh (Image tag mutability): Chọn Có thể thay đổi (Mutable). Trong phần Cài đặt mã hóa (Encryption settings): Chọn AES256. Nhấp vào nút Tạo repository (Create repository). 2 Tạo Docker Image Tạo một thư mục mới có tên ecr-image và điều hướng đến thư mục này. |-- Makefile |-- cmd | `-- task-load-to-s3 | |-- Dockerfile | |-- main.go | `-- processor.go |-- go.mod |-- go.sum Create file main.go in the cmd/task-load-to-s3 directory. package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; \u0026#34;github.com/aws/aws-sdk-go/aws\u0026#34; \u0026#34;github.com/aws/aws-sdk-go/aws/session\u0026#34; ) const ( zippath = \u0026#34;/tmp/yourfile.zip\u0026#34; unzippath = \u0026#34;/tmp/unzipped\u0026#34; ) func main() { zipURL := os.Getenv(\u0026#34;URL_TO_DOWNLOAD\u0026#34;) bucket := os.Getenv(\u0026#34;S3_BUCKET_NAME\u0026#34;) folder := os.Getenv(\u0026#34;S3_FOLDER_NAME\u0026#34;) if zipURL == \u0026#34;\u0026#34; || bucket == \u0026#34;\u0026#34; || folder == \u0026#34;\u0026#34; { log.Fatal(\u0026#34;URL_TO_DOWNLOAD and S3_BUCKET_NAME must be set\u0026#34;) } if folder!=\u0026#34;video\u0026#34; \u0026amp;\u0026amp; folder!=\u0026#34;keyframes\u0026#34; { log.Fatal(\u0026#34;S3_FOLDER_NAME must be either \u0026#39;videos\u0026#39; or \u0026#39;images\u0026#39;\u0026#34;) } // Set up AWS session sess, err := session.NewSession(\u0026amp;aws.Config{ Region: aws.String(\u0026#34;ap-southeast-1\u0026#34;), }) if err != nil { log.Fatalf(\u0026#34;Failed to create AWS session: %v\u0026#34;, err) } processor := NewProcessor(sess, bucket, folder) fmt.Println(\u0026#34;Downloading file from\u0026#34;, zipURL) // Download the zip file err = processor.DownloadZip(zipURL) if err != nil { log.Fatalf(\u0026#34;Failed to download file: %v\u0026#34;, err) } // Unzip the file err = processor.unzip() if err != nil { log.Fatalf(\u0026#34;Failed to unzip file: %v\u0026#34;, err) } fmt.Println(\u0026#34;Uploading file to S3 bucket\u0026#34;, bucket) // Upload unzipped content to S3 err = processor.uploadToS3() if err != nil { log.Fatalf(\u0026#34;Failed to upload to S3: %v\u0026#34;, err) } fmt.Println(\u0026#34;File uploaded successfully\u0026#34;) } Create file processor.go in the cmd/task-load-to-s3 directory. package main import ( \u0026#34;archive/zip\u0026#34; \u0026#34;io\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os\u0026#34; \u0026#34;path/filepath\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;github.com/aws/aws-sdk-go/aws\u0026#34; \u0026#34;github.com/aws/aws-sdk-go/aws/session\u0026#34; \u0026#34;github.com/aws/aws-sdk-go/service/s3\u0026#34; ) type Proccessor struct { sess *session.Session bucket string folder string } func NewProcessor(sess *session.Session, bucket string, folder string) *Proccessor { return \u0026amp;Proccessor{ sess: sess, bucket: bucket, folder: folder, } } func (p *Proccessor) unzip() error { r, err := zip.OpenReader(zippath) if err != nil { return err } defer r.Close() for _, f := range r.File { rc, err := f.Open() if err != nil { return err } defer rc.Close() fpath := filepath.Join(unzippath, f.Name) if f.FileInfo().IsDir() { os.MkdirAll(fpath, os.ModePerm) } else { os.MkdirAll(filepath.Dir(fpath), os.ModePerm) outFile, err := os.Create(fpath) if err != nil { return err } defer outFile.Close() _, err = io.Copy(outFile, rc) if err != nil { return err } } } return nil } func (p *Proccessor) uploadToS3() error { svc := s3.New(p.sess) err := filepath.Walk(unzippath, func(path string, info os.FileInfo, err error) error { if err != nil { return err } if info.IsDir() { return nil } file, err := os.Open(path) if err != nil { return err } defer file.Close() key := filepath.ToSlash(path) key = key[strings.Index(key, p.folder):] key = strings.Replace(key, p.folder, \u0026#34;\u0026#34;, 1) fullKey := filepath.Join(p.folder, key) fullKey = strings.Replace(fullKey, \u0026#34;\\\\\u0026#34;, \u0026#34;/\u0026#34;, -1) _, err = svc.PutObject(\u0026amp;s3.PutObjectInput{ Bucket: aws.String(p.bucket), Key: aws.String(fullKey), Body: file, }) if err != nil { return err } return nil }) return err } func (p *Proccessor) DownloadZip(url string) error { resp, err := http.Get(url) if err != nil { return err } defer resp.Body.Close() out, err := os.Create(zippath) if err != nil { return err } defer out.Close() _, err = io.Copy(out, resp.Body) return err } Create a Dockerfile in the cmd/task-load-to-s3 directory. FROM golang:1.20-alpine3.18 AS builder WORKDIR /app COPY . . RUN go build -o main ./cmd/task-load-to-s3/*.go FROM alpine:3.18 WORKDIR /app COPY --from=builder /app/main . ENTRYPOINT [\u0026#34;/app/main\u0026#34;] Create a Makefile in the root directory. run: go run ./cmd/task-load-to-s3/*.go build: docker build -f ./cmd/task-load-to-s3/Dockerfile -t keyframes:v1 . push: docker tag keyframes:v1 \u0026lt;aws account_id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/ai-challenge-2024:keyframes docker push \u0026lt;aws account_id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/ai-challenge-2024:keyframes Install the required dependencies. go mod init keyframes go mod tidy Run the following command to build the docker image. make build Push the docker image to ECR. Go to the ECR console. Click on the repository ai-challenge-2024. Click on the View push commands button. Run the commands to login to ECR. aws ecr get-login-password --region ap-southeast-1 | docker login --username AWS --password-stdin \u0026lt;aws account_id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com Push the docker image to ECR. make push "
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/vi/3-ingrest-data/3.3-ecs-task/",
	"title": "Create ECS Task Definition",
	"tags": [],
	"description": "Modules",
	"content": "1 Tạo một ECS Cluster Điều hướng đến ECS bằng cách nhấp vào menu Services, dưới phần Compute. Nhấp vào nút Create Cluster. Trong Cluster configuration Cluster name: Nhập ai-challenge-ecs-cluster Trong Infrastructure Provisioning model: Chọn AWS Fargate (serverless) Nhấp vào nút Create Chờ 2 phút để cluster ECS được tạo.\n2 Tạo một ECS Task Role 2.1 Tạo IAM Role Điều hướng đến IAM bằng cách nhấp vào menu Services, dưới phần Security, Identity, \u0026amp; Compliance. Nhấp vào Roles trong thanh điều hướng bên trái. Nhấp vào nút Create role. Trong Select type of trusted entity Chọn AWS service Chọn dịch vụ sẽ sử dụng vai trò này: ECS Nhấp vào nút Next: Permissions Chọn Next để đến trang Review. Trong trang Review. Role name: Nhập TaskRole Nhấp vào nút Create role 2.2 Gán Policies cho Vai Trò Nhấp vào vai trò TaskRole. Nhấp vào nút Add Permission. Nhấp vào nút Create Inline Policy. Chọn tab JSON. Dán JSON này vào trình chỉnh sửa Policy Document. { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::ai-challenge-2024/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:*:*:*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ecr:GetAuthorizationToken\u0026#34;, \u0026#34;ecr:BatchCheckLayerAvailability\u0026#34;, \u0026#34;ecr:GetDownloadUrlForLayer\u0026#34;, \u0026#34;ecr:BatchGetImage\u0026#34;, \u0026#34;logs:CreateLogGroup\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } "
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/vi/3-ingrest-data/3.4-run-task/",
	"title": "Run ECS Task",
	"tags": [],
	"description": "Modules",
	"content": "1 Prepare Script to Run Task import os import boto3 s3_client = boto3.client(\u0026#34;s3\u0026#34;) ecs_client = boto3.client(\u0026#34;ecs\u0026#34;) def lambda_handler(): cluster_name = os.environ[\u0026#34;ECS_CLUSTER_NAME\u0026#34;] task_definition = os.environ[\u0026#34;TASK_DEFINITION\u0026#34;] subnet_id = os.environ[\u0026#34;SUBNET_ID\u0026#34;] security_group_id = os.environ[\u0026#34;SECURITY_GROUP_ID\u0026#34;] # # Cấu hình network cho ECS task network_config = { \u0026#34;awsvpcConfiguration\u0026#34;: { \u0026#34;subnets\u0026#34;: [subnet_id], \u0026#34;securityGroups\u0026#34;: [security_group_id], \u0026#34;assignPublicIp\u0026#34;: \u0026#34;ENABLED\u0026#34;, } } keyframes_urls = [ \u0026#34;https://atm249495-s3user.vcos.cloudstorage.com.vn/aic24-b5/Keyframes_L01.zip\u0026#34;, \u0026#34;https://atm249497-s3user.vcos.cloudstorage.com.vn/aic24-b7/Keyframes_L03.zip\u0026#34;, \u0026#34;https://atm249498-s3user.vcos.cloudstorage.com.vn/aic24-b8/Keyframes_L04.zip\u0026#34;, \u0026#34;https://atm249495-s3user.vcos.cloudstorage.com.vn/aic24-b5/Keyframes_L05.zip\u0026#34;, \u0026#34;https://atm249496-s3user.vcos.cloudstorage.com.vn/aic24-b6/Keyframes_L06.zip\u0026#34;, \u0026#34;https://atm249497-s3user.vcos.cloudstorage.com.vn/aic24-b7/Keyframes_L07.zip\u0026#34;, \u0026#34;https://atm249498-s3user.vcos.cloudstorage.com.vn/aic24-b8/Keyframes_L08.zip\u0026#34;, \u0026#34;https://atm249495-s3user.vcos.cloudstorage.com.vn/aic24-b5/Keyframes_L09.zip\u0026#34;, \u0026#34;https://atm249496-s3user.vcos.cloudstorage.com.vn/aic24-b6/Keyframes_L10.zip\u0026#34;, \u0026#34;https://atm249497-s3user.vcos.cloudstorage.com.vn/aic24-b7/Keyframes_L11.zip\u0026#34;, \u0026#34;https://atm249498-s3user.vcos.cloudstorage.com.vn/aic24-b8/Keyframes_L12.zip\u0026#34;, ] video_urls = [ \u0026#34;https://atm249495-s3user.vcos.cloudstorage.com.vn/aic24-b5/Videos_L01.zip\u0026#34;, \u0026#34;https://atm249496-s3user.vcos.cloudstorage.com.vn/aic24-b6/Videos_L02.zip\u0026#34;, \u0026#34;https://atm249497-s3user.vcos.cloudstorage.com.vn/aic24-b7/Videos_L03.zip\u0026#34;, \u0026#34;https://atm249498-s3user.vcos.cloudstorage.com.vn/aic24-b8/Videos_L04.zip\u0026#34;, \u0026#34;https://atm249495-s3user.vcos.cloudstorage.com.vn/aic24-b5/Videos_L05.zip\u0026#34;, \u0026#34;https://atm249496-s3user.vcos.cloudstorage.com.vn/aic24-b6/Videos_L06.zip\u0026#34;, \u0026#34;https://atm249497-s3user.vcos.cloudstorage.com.vn/aic24-b7/Videos_L07.zip\u0026#34;, \u0026#34;https://atm249498-s3user.vcos.cloudstorage.com.vn/aic24-b8/Videos_L08.zip\u0026#34;, \u0026#34;https://atm249495-s3user.vcos.cloudstorage.com.vn/aic24-b5/Videos_L09.zip\u0026#34;, \u0026#34;https://atm249496-s3user.vcos.cloudstorage.com.vn/aic24-b6/Videos_L10.zip\u0026#34;, \u0026#34;https://atm249497-s3user.vcos.cloudstorage.com.vn/aic24-b7/Videos_L11.zip\u0026#34;, \u0026#34;https://atm249498-s3user.vcos.cloudstorage.com.vn/aic24-b8/Videos_L12.zip\u0026#34;, ] for zip_file_url in keyframes_urls: run_task_input = { \u0026#34;cluster\u0026#34;: cluster_name, \u0026#34;launchType\u0026#34;: \u0026#34;FARGATE\u0026#34;, \u0026#34;taskDefinition\u0026#34;: task_definition, \u0026#34;networkConfiguration\u0026#34;: network_config, \u0026#34;overrides\u0026#34;: { \u0026#34;containerOverrides\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;keyframes-container\u0026#34;, \u0026#34;environment\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;URL_TO_DOWNLOAD\u0026#34;, \u0026#34;value\u0026#34;: zip_file_url, }, { \u0026#34;name\u0026#34;: \u0026#34;S3_BUCKET_NAME\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;ai-challenge-2024\u0026#34;, }, { \u0026#34;name\u0026#34;: \u0026#34;S3_FOLDER_NAME\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;keyframes\u0026#34;, }, ], } ] }, } response = ecs_client.run_task(**run_task_input) for zip_file_url in video_urls: run_task_input = { \u0026#34;cluster\u0026#34;: cluster_name, \u0026#34;launchType\u0026#34;: \u0026#34;FARGATE\u0026#34;, \u0026#34;taskDefinition\u0026#34;: task_definition, \u0026#34;networkConfiguration\u0026#34;: network_config, \u0026#34;overrides\u0026#34;: { \u0026#34;containerOverrides\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;keyframes-container\u0026#34;, \u0026#34;environment\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;URL_TO_DOWNLOAD\u0026#34;, \u0026#34;value\u0026#34;: zip_file_url, }, { \u0026#34;name\u0026#34;: \u0026#34;S3_BUCKET_NAME\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;ai-challenge-2024\u0026#34;, }, { \u0026#34;name\u0026#34;: \u0026#34;S3_FOLDER_NAME\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;video\u0026#34;, }, ], } ] }, } response = ecs_client.run_task(**run_task_input) return { \u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: f\u0026#39;Task created successfully with Task ARN: {response[\u0026#34;tasks\u0026#34;][0][\u0026#34;taskArn\u0026#34;]}\u0026#39;, } if __name__ == \u0026#34;__main__\u0026#34;: lambda_handler() Biến Môi Trường\nDưới đây là các biến môi trường chính cần thiết để thiết lập và chạy tác vụ ECS:\nECS_CLUSTER_NAME: Xác định tên của cụm ECS nơi tác vụ sẽ được triển khai. TASK_DEFINITION: Định nghĩa tên của định nghĩa tác vụ ECS được sử dụng cho tác vụ. SUBNET_ID: ID của subnet nơi tác vụ ECS sẽ được khởi chạy, xác định mạng trong VPC. SECURITY_GROUP_ID: ID của nhóm bảo mật xác định các quy tắc tường lửa và quyền truy cập cho tác vụ ECS. CONTAINER_NAME: Xác định tên của container trong định nghĩa tác vụ ECS. Cấu Hình Ví Dụ\nECS_CLUSTER_NAME: ai-challenge-2024\nTASK_DEFINITION: keyframes-task\nSUBNET_ID: subnet-0f9d3b7b1b7b7b7b7\nSECURITY_GROUP_ID: sg-0f9d3b7b1b7b7b7b7\nCONTAINER_NAME: keyframes-container\nMỗi biến này đóng vai trò quan trọng trong việc thiết lập tác vụ, đảm bảo triển khai và kiểm soát truy cập đúng cách trong môi trường AWS của bạn.\n2 Chạy Tác Vụ Chạy script để nạp dữ liệu vào S3:\npython run_task.py "
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/vi/4-process-data/",
	"title": "Feature Extraction Using SageMaker and ECS",
	"tags": [],
	"description": "Learn how to build a Semantic Video Search Vector Database using AWS services such as SageMaker, S3, OpenSearch, ECS Fargate, and Lambda.",
	"content": "Overview In this module, you will learn how to extract meaningful features from video data using Amazon SageMaker and ECS. We will guide you through the process of setting up SageMaker, creating a feature extraction pipeline, and deploying the pipeline on ECS Fargate to process video data efficiently.\nContents Extract Keyframes Using ECS\nEmbedding Processing with SageMaker\n"
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/vi/4-process-data/4.1-extract-keyframes-ecs/",
	"title": "Extract Keyframes Using ECS",
	"tags": [],
	"description": "Learn how to build a Semantic Video Search Vector Database using AWS services such as SageMaker, S3, OpenSearch, ECS Fargate, and Lambda.",
	"content": "1 Create Docker Image for Keyframes Extraction Create a new directory called ecr-extract-keyframes and navigate to it. . |-- Dockerfile |-- get-object-s3.py |-- requirements.txt |-- run-task.py |-- split-video.py Create file Dockerfile in the directory. FROM python:3.9-slim RUN apt-get update \u0026amp;\u0026amp; \\ apt-get install -y \\ libgl1-mesa-glx \\ libglib2.0-0 \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* COPY requirements.txt . RUN pip install --no-cache-dir -r requirements.txt COPY . /app WORKDIR /app CMD [\u0026#34;python\u0026#34;, \u0026#34;extract-keyframes.py\u0026#34;] Create file extract-keyframes.py in the directory. import boto3 import cv2 import os import numpy as np import tempfile import csv from io import StringIO class S3KeyframeUpdater: def __init__(self, bucket_name, video_key, folder_prefix, output_csv_key): self.bucket_name = bucket_name self.video_key = video_key self.folder_prefix = folder_prefix self.output_csv_key = output_csv_key self.s3 = boto3.client(\u0026#39;s3\u0026#39;) def list_s3_objects(self, prefix): response = self.s3.list_objects_v2(Bucket=self.bucket_name, Prefix=prefix) if \u0026#39;Contents\u0026#39; in response: return [obj[\u0026#39;Key\u0026#39;] for obj in response[\u0026#39;Contents\u0026#39;]] return [] def get_s3_object(self, key): return self.s3.get_object(Bucket=self.bucket_name, Key=key)[\u0026#39;Body\u0026#39;].read() def update_keyframe_metadata(self): print(f\u0026#39;Download video from {self.video_key}\u0026#39;) video_data = self.get_s3_object(self.video_key) with tempfile.NamedTemporaryFile(delete=False, suffix=\u0026#39;.mp4\u0026#39;) as temp_video_file: temp_video_file.write(video_data) temp_video_path = temp_video_file.name video = cv2.VideoCapture(temp_video_path) keyframe_keys = self.list_s3_objects(self.folder_prefix) number_of_keyframes = len(keyframe_keys) count = 0 frame_number = 0 csv_buffer = StringIO() csv_writer = csv.writer(csv_buffer) csv_writer.writerow([\u0026#39;VideoName\u0026#39;, \u0026#39;KeyframeName\u0026#39;, \u0026#39;FrameNumber\u0026#39;]) while True: ret, frame = video.read() if not ret or count \u0026gt;= number_of_keyframes: break gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) keyframe_data = self.get_s3_object(keyframe_keys[count]) keyframe_img = cv2.imdecode(np.frombuffer(keyframe_data, np.uint8), cv2.IMREAD_GRAYSCALE) result = cv2.matchTemplate(gray_frame, keyframe_img, cv2.TM_CCOEFF_NORMED) _, max_val, _, _ = cv2.minMaxLoc(result) if max_val \u0026gt; 0.9: name = os.path.basename(keyframe_keys[count]) self.s3.copy_object( Bucket=self.bucket_name, CopySource={\u0026#39;Bucket\u0026#39;: self.bucket_name, \u0026#39;Key\u0026#39;: keyframe_keys[count]}, Key=keyframe_keys[count], MetadataDirective=\u0026#39;REPLACE\u0026#39;, Metadata={ \u0026#39;VideoKey\u0026#39;: self.video_key, \u0026#39;FrameNumber\u0026#39;: str(frame_number) } ) print(f\u0026#39;Updated metadata for {name} at frame {frame_number}\u0026#39;) csv_writer.writerow([os.path.basename(self.video_key), name, frame_number]) count += 1 frame_number += 1 video.release() os.remove(temp_video_path) csv_buffer.seek(0) self.s3.put_object( Bucket=self.bucket_name, Key=self.output_csv_key, Body=csv_buffer.getvalue(), ContentType=\u0026#39;text/csv\u0026#39; ) print(f\u0026#39;Result has saved to {self.output_csv_key} on S3\u0026#39;) if __name__ == \u0026#34;__main__\u0026#34;: bucket_name = os.environ[\u0026#39;BUCKET_NAME\u0026#39;] folder_prefix = os.environ[\u0026#39;FOLDER_PREFIX\u0026#39;] video_key = os.environ[\u0026#39;VIDEO_KEY\u0026#39;] output_csv_key = f\u0026#39;metadata/{video_key.split(\u0026#34;/\u0026#34;)[1].split(\u0026#34;.\u0026#34;)[0]}.csv\u0026#39; if not bucket_name or not folder_prefix or not video_key: raise ValueError(\u0026#39;Missing environment variables\u0026#39;) print(\u0026#34;Start updating keyframe metadata: \u0026#34;, bucket_name, video_key, folder_prefix, output_csv_key) updater = S3KeyframeUpdater(bucket_name, video_key, folder_prefix, output_csv_key) updater.update_keyframe_metadata() Create a requirements.txt in the directory. boto3 opencv-python-headless numpy Build the docker image. docker build -t ai-challenge-2024:keyframe-matcher . Tag the docker image. docker tag ai-challenge-2024:keyframe-matcher \u0026lt;aws account_id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/ai-challenge-2024:keyframe-matcher Push the docker image to ECR. Go to the ECR console. Click on the repository ai-challenge-2024. Click on the View push commands button. Run the commands to login to ECR. aws ecr get-login-password --region ap-southeast-1 | docker login --username AWS --password-stdin \u0026lt;aws account_id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com Push the docker image to ECR. docker push \u0026lt;aws account_id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/ai-challenge-2024:keyframe-matcher Create Task Definition Click on Task Definitions in the left navigation pane. Click on Create new Task Definition button. Select Create new task with JSON Paste this json in the Task Definition editor. { \u0026#34;containerDefinitions\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;keyframe-matcher-container-min\u0026#34;, \u0026#34;image\u0026#34;: \u0026#34;\u0026lt;aws account id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/ai-challenge-2024:keyframe-matcher\u0026#34;, \u0026#34;cpu\u0026#34;: 512, \u0026#34;memory\u0026#34;: 2048, \u0026#34;portMappings\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;80\u0026#34;, \u0026#34;containerPort\u0026#34;: 80, \u0026#34;hostPort\u0026#34;: 80, \u0026#34;protocol\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;appProtocol\u0026#34;: \u0026#34;http\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;433\u0026#34;, \u0026#34;containerPort\u0026#34;: 443, \u0026#34;hostPort\u0026#34;: 443, \u0026#34;protocol\u0026#34;: \u0026#34;tcp\u0026#34;, \u0026#34;appProtocol\u0026#34;: \u0026#34;http\u0026#34; } ], \u0026#34;essential\u0026#34;: true, \u0026#34;environment\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;FOLDER_PREFIX\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;VIDEO_KEY\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;BUCKET_NAME\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;\u0026#34; } ], \u0026#34;logConfiguration\u0026#34;: { \u0026#34;logDriver\u0026#34;: \u0026#34;awslogs\u0026#34;, \u0026#34;options\u0026#34;: { \u0026#34;awslogs-group\u0026#34;: \u0026#34;/ecs/keyframe-matcher-definition-min\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;non-blocking\u0026#34;, \u0026#34;awslogs-create-group\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;max-buffer-size\u0026#34;: \u0026#34;25m\u0026#34;, \u0026#34;awslogs-region\u0026#34;: \u0026#34;ap-southeast-1\u0026#34;, \u0026#34;awslogs-stream-prefix\u0026#34;: \u0026#34;ecs\u0026#34; }, \u0026#34;secretOptions\u0026#34;: [] }, \u0026#34;systemControls\u0026#34;: [] } ], \u0026#34;family\u0026#34;: \u0026#34;keyframe-matcher-definition-min\u0026#34;, \u0026#34;taskRoleArn\u0026#34;: \u0026#34;arn:aws:iam::\u0026lt;aws account id\u0026gt;:role/TaskRole\u0026#34;, \u0026#34;executionRoleArn\u0026#34;: \u0026#34;arn:aws:iam::\u0026lt;aws account id\u0026gt;:role/TaskRole\u0026#34;, \u0026#34;networkMode\u0026#34;: \u0026#34;awsvpc\u0026#34;, \u0026#34;revision\u0026#34;: 1, \u0026#34;status\u0026#34;: \u0026#34;ACTIVE\u0026#34;, \u0026#34;compatibilities\u0026#34;: [ \u0026#34;EC2\u0026#34;, \u0026#34;FARGATE\u0026#34; ], \u0026#34;requiresCompatibilities\u0026#34;: [ \u0026#34;FARGATE\u0026#34; ], \u0026#34;cpu\u0026#34;: \u0026#34;512\u0026#34;, \u0026#34;memory\u0026#34;: \u0026#34;2048\u0026#34;, \u0026#34;runtimePlatform\u0026#34;: { \u0026#34;cpuArchitecture\u0026#34;: \u0026#34;X86_64\u0026#34;, \u0026#34;operatingSystemFamily\u0026#34;: \u0026#34;LINUX\u0026#34; }, } The core configuration specifying how the container runs within the task:\nContainer Definitions\nname: keyframe-matcher-container-min – The name of the container.\nimage: \u0026lt;aws account id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/ai-challenge-2024:keyframe-matcher – The Docker image stored in Amazon ECR that the container will use.\ncpu: 512 – Allocates 0.5 vCPUs to the container.\nmemory: 2048 – Allocates 2 GB of memory to the container.\nportMappings:\ncontainerPort: 80 – Exposes port 80 for HTTP traffic. containerPort: 433 – Exposes port 433 for traffic (note: may need correction to 443 for HTTPS). essential: true – Indicates that the container is critical for the task; if this container stops, the entire task will stop.\nEnvironment Variables Environment variables passed to the container to configure behavior:\nFOLDER_PREFIX: \u0026quot;\u0026quot; – The prefix for the S3 folder containing keyframes. VIDEO_KEY: \u0026quot;\u0026quot; – The S3 key for the video file to process. BUCKET_NAME: \u0026quot;\u0026quot; – The name of the S3 bucket containing the video and keyframes. Logging Configuration Sets up logging to AWS CloudWatch Logs for monitoring and debugging:\nlogDriver: awslogs – Uses the AWS Logs driver to send logs to CloudWatch. awslogs-group: /ecs/keyframe-matcher-definition-min – Specifies the CloudWatch Logs group where logs are stored. awslogs-create-group: true – Automatically creates the log group if it does not exist. max-buffer-size: 25m – Specifies the maximum buffer size for logs. awslogs-region: ap-southeast-1 – Sets the AWS region for logging. awslogs-stream-prefix: ecs – Adds a prefix to log streams to help identify them easily. Task-Level Settings\nfamily: \u0026quot;keyframe-matcher-definition-min\u0026quot; – The family name of the task, used to identify it in ECS. taskRoleArn: arn:aws:iam::\u0026lt;aws account id\u0026gt;:role/TaskRole – Specifies the IAM role that grants the task permissions to interact with AWS services. executionRoleArn: arn:aws:iam::\u0026lt;aws account id\u0026gt;:role/TaskRole – Specifies the IAM role used by the ECS agent to pull images and publish logs. Network Configuration\nnetworkMode: awsvpc – Uses the AWS VPC network mode, allowing the task to have its own network interfaces, security groups, and elastic network interfaces. requiresCompatibilities: [\u0026quot;FARGATE\u0026quot;] – Specifies that the task requires Fargate launch type. Resource Configuration\ncpu: \u0026quot;512\u0026quot; – Allocates 0.5 vCPUs to the task. memory: \u0026quot;2048\u0026quot; – Allocates 2 GB of memory to the task. ephemeralStorage sizeInGiB: 21 – Provides 21 GB of ephemeral storage for temporary data generated by the task. Platform Configuration\nruntimePlatform: cpuArchitecture: X86_64 – Specifies the CPU architecture. operatingSystemFamily: LINUX – Specifies the operating system family used. After pasting the JSON, click on Create button. We have successfully created a task definition for extracting keyframes from videos.\n3 Run Task to Extract Keyframes 3.1 Prepare Script to Run Task Create run-task.py in the ecr-extract-keyframes directory. This script will run the task definition to extract keyframes from a video file.\nimport os import boto3 s3_client = boto3.client(\u0026#34;s3\u0026#34;) ecs_client = boto3.client(\u0026#34;ecs\u0026#34;) def lambda_handler(event, context): cluster_name = os.environ[\u0026#34;ECS_CLUSTER_NAME\u0026#34;] task_definition = os.environ[\u0026#34;TASK_DEFINITION\u0026#34;] subnet_ids = os.environ[\u0026#34;SUBNET_IDS\u0026#34;] security_group_id = os.environ[\u0026#34;SECURITY_GROUP_ID\u0026#34;] container_name = os.environ[\u0026#34;CONTAINER_NAME\u0026#34;] network_config = { \u0026#34;awsvpcConfiguration\u0026#34;: { \u0026#34;subnets\u0026#34;: subnet_ids, \u0026#34;securityGroups\u0026#34;: [security_group_id], \u0026#34;assignPublicIp\u0026#34;: \u0026#34;ENABLED\u0026#34;, } } FOLDERS = [] response = s3.list_objects_v2(Bucket=BUCKET_NAME, Prefix=PREFIX, Delimiter=\u0026#39;/\u0026#39;) # Get the subfolders in the bucket if \u0026#39;CommonPrefixes\u0026#39; in response: subfolders = [prefix.get(\u0026#39;Prefix\u0026#39;) for prefix in response[\u0026#39;CommonPrefixes\u0026#39;]] for subfolder in subfolders: FOLDERS.append(subfolder) else: print(\u0026#34;No subfolders found.\u0026#34;) for folder in FOLDERS: run_task_input = { \u0026#34;cluster\u0026#34;: cluster_name, \u0026#34;launchType\u0026#34;: \u0026#34;FARGATE\u0026#34;, \u0026#34;taskDefinition\u0026#34;: task_definition, \u0026#34;networkConfiguration\u0026#34;: network_config, \u0026#34;overrides\u0026#34;: { \u0026#34;containerOverrides\u0026#34;: [ { \u0026#34;name\u0026#34;: container_name, \u0026#34;environment\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;BUCKET_NAME\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;ai-challenge-2024\u0026#34;, }, { \u0026#34;name\u0026#34;: \u0026#34;FOLDER_PREFIX\u0026#34;, \u0026#34;value\u0026#34;: folder, }, { \u0026#34;name\u0026#34;: \u0026#34;VIDEO_KEY\u0026#34;, \u0026#34;value\u0026#34;: f\u0026#34;video/{folder.split(\u0026#34;/\u0026#34;)[1]}.mp4\u0026#34;, }, ], } ] }, } response = ecs_client.run_task(**run_task_input) return { \u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: f\u0026#39;Task created successfully with Task ARN: {response[\u0026#34;tasks\u0026#34;][0][\u0026#34;taskArn\u0026#34;]}\u0026#39;, } if __name__ == \u0026#34;__main__\u0026#34;: event = {} context = None lambda_handler(event, context) Environment Variables:\nECS_CLUSTER_NAME: The name of the ECS cluster where the task will run. TASK_DEFINITION: The ARN of the task definition created in the previous step. SUBNET_IDS: The ID of the subnets where the task will run. SECURITY_GROUP_ID: The ID of the security group for the task. CONTAINER_NAME: The name of the container in the task definition. Example Values:\nECS_CLUSTER_NAME: ai-challenge-2024-cluster TASK_DEFINITION: arn:aws:ecs:ap-southeast-1:\u0026lt;aws account id\u0026gt;:task-definition/keyframe-matcher-definition-min:1 SUBNET_IDS: [\u0026quot;subnet-0a1b2c3d4e5f6g7h\u0026quot;,\u0026quot;subnet-1a2b3c4d5e6f7g8\u0026quot;] SECURITY_GROUP_ID: sg-0123456789abcdef0 CONTAINER_NAME: keyframe-matcher-container-min 3.2 Run Task By Local CLI Run the script to create a task to extract keyframes from the video file.\npython run-task.py The script will create a task in the ECS cluster to extract keyframes from the video file. You can monitor the task status in the ECS console.\n3.3 Verify Keyframes Extraction After the task completes, you can verify that the keyframes have been extracted and updated with metadata in the S3 bucket.\nNavigate to the S3 console. Open the bucket ai-challenge-2024. Check the keyframes folder for the extracted keyframes. Verify that the keyframes have been updated with metadata in the S3 console. Video Key: The S3 key of the video file. Frame Number: The frame number in the video where the keyframe was found. Check results in the metadata folder for the CSV file containing the keyframe metadata. "
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/vi/4-process-data/4.2-embedding-processing-sagemaker/",
	"title": "Embedding Processing with SageMaker",
	"tags": [],
	"description": "Learn how to build a Semantic Video Search Vector Database using AWS services such as SageMaker, S3, OpenSearch, ECS Fargate, and Lambda.",
	"content": "1.Prepare Script for Embedding Processing Create a folder embedding-processing and navigate to it. |-- main.ipynb |-- requirements.txt `-- script.py Create a main.ipynb file in the embedding-processing directory. Import Libraries import sagemaker import boto3 from PIL import Image from io import BytesIO import matplotlib.pyplot as plt import sagemaker from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput Set Up SageMaker Session s3 = boto3.client(\u0026#39;s3\u0026#39;) sess = sagemaker.Session() BUCKET_NAME = \u0026#34;ai-challenge-2024\u0026#34; PREFIX = \u0026#34;keyframes/\u0026#34; OUTPUT_PREFIX = \u0026#34;keyframes-processed/\u0026#34; FOLDERS = []\rresponse = s3.list_objects_v2(Bucket=BUCKET_NAME, Prefix=PREFIX, Delimiter=\u0026#39;/\u0026#39;)\r# Get the subfolders in the bucket\rif \u0026#39;CommonPrefixes\u0026#39; in response:\rsubfolders = [prefix.get(\u0026#39;Prefix\u0026#39;) for prefix in response[\u0026#39;CommonPrefixes\u0026#39;]]\rfor subfolder in subfolders:\rFOLDERS.append(subfolder)\relse:\rprint(\u0026#34;No subfolders found.\u0026#34;) Show Sample Image # Get exmaple file in each subfolder example_folder = FOLDERS[0] files = s3.list_objects_v2(Bucket=BUCKET_NAME, Prefix=example_folder) plt.figure(figsize=(20, 10)) for i in range(1, 5): example_file = files[\u0026#39;Contents\u0026#39;][i][\u0026#39;Key\u0026#39;] example_img = s3.get_object(Bucket=BUCKET_NAME, Key=example_file)[\u0026#34;Body\u0026#34;].read() img = Image.open(BytesIO(example_img)) plt.subplot(1, 4, i) plt.imshow(img) plt.show() Script Processor %%writefile script.py import os import sys import subprocess subprocess.check_call( [ sys.executable, \u0026#34;-m\u0026#34;, \u0026#34;pip\u0026#34;, \u0026#34;install\u0026#34;, \u0026#34;-r\u0026#34;, \u0026#34;/opt/ml/processing/code/requirements.txt\u0026#34;, ] ) import torch from sentence_transformers import SentenceTransformer from PIL import Image import numpy def processor(input_dir, output_dir): print(\u0026#34;Loading model.....\u0026#34;) model = SentenceTransformer(\u0026#34;clip-ViT-B-32\u0026#34;) print(\u0026#34;Model loaded\u0026#34;) device = \u0026#34;cuda\u0026#34; if torch.cuda.is_available() else \u0026#34;cpu\u0026#34; model = model.to(device) print(f\u0026#34;Using device: {device}\u0026#34;) folders = os.listdir(input_dir) for folder in folders: # Ignore : \u0026#39;/opt/ml/processing/input/code/script.py\u0026#39; if folder == \u0026#34;code\u0026#34;: continue image_paths = os.listdir(os.path.join(input_dir, folder)) images = [] for image_path in image_paths: image = Image.open(os.path.join(input_dir, folder, image_path)) images.append(image) embeddings = model.encode(images) numpy.save(os.path.join(output_dir, f\u0026#34;{folder}.npy\u0026#34;), embeddings) print(f\u0026#34;Embeddings for {folder} saved\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: input_dir = \u0026#34;/opt/ml/processing/input\u0026#34; output_dir = \u0026#34;/opt/ml/processing/output\u0026#34; # Local testing # input_dir = \u0026#34;./dataset/keyframes\u0026#34; # output_dir = \u0026#34;./dataset/output\u0026#34; print(\u0026#34;Starting processing.....\u0026#34;) processor(input_dir, output_dir) print(\u0026#34;Processing complete\u0026#34;) Requirements.txt %%writefile requirements.txt sentence_transformers pillow Upload requirements.txt to S3 s3.upload_file(\u0026#34;requirements.txt\u0026#34;, BUCKET_NAME, \u0026#34;code/requirements.txt\u0026#34;) Start processing job role = sagemaker.get_execution_role() image_uri = sagemaker.image_uris.retrieve( framework=\u0026#39;pytorch\u0026#39;, region=sess.boto_region_name, version=\u0026#39;1.9\u0026#39;, py_version=\u0026#39;py38\u0026#39;, instance_type=\u0026#39;ml.m5.xlarge\u0026#39;, image_scope=\u0026#39;training\u0026#39; ) script_processor = ScriptProcessor( image_uri=image_uri, command=[\u0026#39;python3\u0026#39;], role=role, instance_count=1, instance_type=\u0026#39;ml.m5.xlarge\u0026#39;, sagemaker_session=sess ) input_s3_uri = \u0026#39;s3://{}/{}/\u0026#39;.format(BUCKET_NAME, PREFIX) output_s3_uri = \u0026#39;s3://{}/{}/\u0026#39;.format(BUCKET_NAME, OUTPUT_PREFIX) processing_inputs = [ ProcessingInput( source=input_s3_uri, destination=\u0026#39;/opt/ml/processing/input\u0026#39; ), ProcessingInput( source=\u0026#39;s3://{}/code/\u0026#39;.format(BUCKET_NAME), destination=\u0026#39;/opt/ml/processing/code\u0026#39; ) ] processing_outputs = [ ProcessingOutput( source=\u0026#39;/opt/ml/processing/output\u0026#39;, destination=output_s3_uri ) ] script_processor.run( code=\u0026#39;script.py\u0026#39;, inputs=processing_inputs, outputs=processing_outputs, logs=True ) Note: If you encounter an error related to the quota limit, you can request a limit increase by following the instructions.\n2.Monitor Processing Job You can monitor the processing job by navigating to the SageMaker console and selecting the Processing jobs tab. You will see the job status, logs, and other details related to the processing job.\n3.Check Output Data in S3 Once the processing job is complete, you can check the output data in the S3 bucket. Navigate to the S3 console and locate the embeddings folder to view the processed embeddings.\n"
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/vi/5-vectordb-opensearch/",
	"title": "Implementing OpenSearch for Vector Database",
	"tags": [],
	"description": "Learn how to build a Semantic Video Search Vector Database using AWS services such as SageMaker, S3, OpenSearch, ECS Fargate, and Lambda.",
	"content": "Overview Welcome to the \u0026ldquo;Implementing OpenSearch for Vector Database\u0026rdquo; module! In this module, we will guide you through setting up and using OpenSearch as a vector database for storing and querying video vectors. You will learn how to configure OpenSearch, index video features, and perform semantic searches efficiently.\nContents Set Up OpenSearch Cluster Create Index and Indexing Data With Python SDK Query by Text "
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/vi/5-vectordb-opensearch/5.1-set-up-cluster/",
	"title": "Set Up OpenSearch Cluster",
	"tags": [],
	"description": "Learn how to build a Semantic Video Search Vector Database using AWS services such as SageMaker, S3, OpenSearch, ECS Fargate, and Lambda.",
	"content": "Create an OpenSearch Domain Navigate to OpenSearch by clicking on the Services menu, under the Analytics section.\nClick on Create domain button.\nIn the Name :\nDomain name: Enter semantic-search-domain Domain creation method: Select Standard create\nTemplates: Select Dev/test\nIn the Deployment option(s):\nChoose Domain without standby Select 1AZ In the Data nodes:\nInstance type: Select t3.small.search Number of data nodes: Enter 1 Storage type: Select EBS with 10GB storage of General Purpose SSD (gp3) Network mode : Select Public access\nFine-grained access control:\nSelect Create master user Master user name: Enter admin Master password: Enter \u0026lt;password\u0026gt; Access policy:\nSelect Allow open access to the domain Click on Create domain button\nWait for the domain to be created. Once the domain is created, you will see the domain status as Active.\n"
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/vi/5-vectordb-opensearch/5.2-create-index-and-indexing-data/",
	"title": "Create Index and Indexing Data With Python SDK",
	"tags": [],
	"description": "Learn how to build a Semantic Video Search Vector Database using AWS services such as SageMaker, S3, OpenSearch, ECS Fargate, and Lambda.",
	"content": "1 Prepare Script to Create Index and Indexing Data Create a Python script to create an index and index data in the OpenSearch domain. The script will perform the following tasks: Delete the index if it exists. Create an index with KNN settings. Create a map embedding from the embeddings directory. Bulk add documents to the index from the map embedding jsonl file. Before running the script, make sure to download the embeddings from the s3 bucket to the local machine. The embeddings are stored in the embeddings directory. import os import json import numpy from opensearchpy import OpenSearch, helpers , RequestsHttpConnection class SemanticSearch: def __init__(self, host, port, user, password, index_name): self.client = OpenSearch( hosts=[{\u0026#34;host\u0026#34;: host, \u0026#34;port\u0026#34;: port}], http_auth=(user, password), use_ssl=True, verify_certs=True, connection_class=RequestsHttpConnection, timeout = 120, max_retries = 5, retry_on_timeout = True ) self.index_name = index_name def delete_index(self): try: response = self.client.indices.delete(index=self.index_name) print(f\u0026#34;Index \u0026#39;{self.index_name}\u0026#39; deleted successfully:\u0026#34;, response) except Exception as e: print(f\u0026#34;Error deleting index \u0026#39;{self.index_name}\u0026#39;:\u0026#34;, e) def create_index(self): index_body = { \u0026#34;settings\u0026#34;: {\u0026#34;index\u0026#34;: {\u0026#34;knn\u0026#34;: True}}, \u0026#34;mappings\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;image_embedding\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;knn_vector\u0026#34;, \u0026#34;dimension\u0026#34;: 512, \u0026#34;method\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hnsw\u0026#34;, \u0026#34;engine\u0026#34;: \u0026#34;faiss\u0026#34;, \u0026#34;space_type\u0026#34;: \u0026#34;l2\u0026#34;, \u0026#34;parameters\u0026#34;: { \u0026#34;ef_construction\u0026#34;: 256, \u0026#34;m\u0026#34;: 48, }, }, }, \u0026#34;video\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;}, \u0026#34;image\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34;}, } }, } # Tạo index response = self.client.indices.create(index=self.index_name, body=index_body) print(f\u0026#34;Index created: {response}\u0026#34;) def create_map_embedding(self, embedding_dir): files = os.listdir(embedding_dir) map_embedding = [] for file in files: embeddings = numpy.load(f\u0026#34;{embedding_dir}/{file}\u0026#34;) for i, embedding in enumerate(embeddings): map_embedding.append( { \u0026#34;video\u0026#34;: file, \u0026#34;image\u0026#34;: i + 1, \u0026#34;image_embedding\u0026#34;: embedding.tolist(), } ) # save to jsonl file with open(\u0026#34;map_embedding.jsonl\u0026#34;, \u0026#34;w\u0026#34;) as f: for i, doc in enumerate(map_embedding): f.write( json.dumps( { \u0026#34;_op_type\u0026#34;: \u0026#34;index\u0026#34;, \u0026#34;_index\u0026#34;: self.index_name, \u0026#34;_id\u0026#34;: i + 1, \u0026#34;_source\u0026#34;: { \u0026#34;image_embedding\u0026#34;: doc[\u0026#34;image_embedding\u0026#34;], \u0026#34;image\u0026#34;: doc[\u0026#34;image\u0026#34;], \u0026#34;video\u0026#34;: doc[\u0026#34;video\u0026#34;], }, } ) ) f.write(\u0026#34;\\n\u0026#34;) def bulk_add_documents(self, file_path): actions = [] with open(file_path, \u0026#34;r\u0026#34;) as f: for line in f: document = json.loads(line.strip()) actions.append(document) if len(actions) \u0026gt;= 1000: helpers.bulk(self.client, actions) print(\u0026#34;Batch added: \u0026#34; , len(actions)) actions = [] if actions: helpers.bulk(self.client, actions) # Sử dụng class SemanticSearch host = \u0026#34;\u0026lt;your-opensearch-endpoint\u0026gt;\u0026#34; port = 443 user = \u0026#34;\u0026lt;your-opensearch-user\u0026gt;\u0026#34; password = \u0026#34;\u0026lt;your-opensearch-password\u0026gt;\u0026#34; index_name = \u0026#34;semantic-index\u0026#34; search_system = SemanticSearch(host, port, user, password, index_name) search_system.delete_index() search_system.create_index() search_system.create_map_embedding(\u0026#34;embeddings\u0026#34;) search_system.bulk_add_documents(\u0026#34;map_embedding.jsonl\u0026#34;) Explain the code: delete_index() : Xóa index nếu tồn tại. create_index() : Tạo index với cấu hình KNN (dimension = 512, method = hnsw, engine = faiss, space_type = l2). create_map_embedding() : Tạo map embedding từ các file embedding trong thư mục embeddings theo định dạng jsonl. bulk_add_documents() : Thêm các documents vào index từ file jsonl theo batch size 1000. Monitoring the Cluster 1. Check Cluster Health Navigate to OpenSearch by clicking on the Domain menu, click on the domain name semantic-search-domain. In the Overview tab, you can see the Cluster health status. After indexing the data, we will see total dcouments is 105k "
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/vi/5-vectordb-opensearch/5.3-query-by-text/",
	"title": "Query by Text",
	"tags": [],
	"description": "Learn how to build a Semantic Video Search Vector Database using AWS services such as SageMaker, S3, OpenSearch, ECS Fargate, and Lambda.",
	"content": "1 Script to Query by Text 1.1 Set up client and model embedding. # code for testing host = \u0026#34;\u0026lt;your opensearch domain\u0026gt;\u0026#34; port = 443 user = \u0026#34;\u0026lt;your master user\u0026gt;\u0026#34; password = \u0026#34;\u0026lt;your master password\u0026gt;\u0026#34; client = OpenSearch( hosts=[{\u0026#34;host\u0026#34;: host, \u0026#34;port\u0026#34;: port}], http_auth=(user, password), use_ssl=True, verify_certs=True, connection_class=RequestsHttpConnection, timeout = 60, # max_retries = 5, # retry_on_timeout = True ) s3 = boto3.client(\u0026#34;s3\u0026#34;) BUCKET_NAME = \u0026#34;ai-challenge-2024\u0026#34; FOLDER_NAME = \u0026#34;keyframes\u0026#34; model = SentenceTransformer(\u0026#34;clip-ViT-B-32\u0026#34;) 1.2 Query by Text def query(client , model , text , k=5): index_name = \u0026#34;semantic-index\u0026#34; query_vector = model.encode(text) search_body = { \u0026#34;size\u0026#34;: k, \u0026#34;query\u0026#34;: { \u0026#34;knn\u0026#34;: { \u0026#34;image_embedding\u0026#34;: { \u0026#34;vector\u0026#34;: query_vector.tolist(), \u0026#34;k\u0026#34;: k, } } }, } result = [] # { # \u0026#34;image\u0026#34; : 1, # \u0026#34;video\u0026#34; : \u0026#34;video1.mp4\u0026#34; # \u0026#34;score\u0026#34; : 1 # } response = client.search(index=index_name, body=search_body) response = response[\u0026#34;hits\u0026#34;][\u0026#34;hits\u0026#34;] for hit in response: image = hit[\u0026#34;_source\u0026#34;][\u0026#34;image\u0026#34;] video = hit[\u0026#34;_source\u0026#34;][\u0026#34;video\u0026#34;] score = hit[\u0026#34;_score\u0026#34;] result.append({\u0026#34;image\u0026#34; : image , \u0026#34;video\u0026#34; : video , \u0026#34;score\u0026#34; : score}) return result result_query = query(client=client , model=model , text=\u0026#34;A drowning prevention drill is taking place. Flooding occurs, and soldiers are deployed to schools to clean up the floodwaters\u0026#34; , k=5) print(result_query) 1.3 Visualize the Result def convert_to_s3_key(video, image): #video L03_V025.npy =\u0026gt; L03_V025 # image 18 =\u0026gt; 018.jpg # image 1 =\u0026gt; 001.jpg video = video.split(\u0026#34;.\u0026#34;)[0] image = str(image).zfill(3) + \u0026#34;.jpg\u0026#34; return video + \u0026#34;/\u0026#34; + image fig = plt.figure(figsize=(20, 10)) for res in result_query: fig.add_subplot(1, 5, result_query.index(res) + 1) img = s3.get_object(Bucket=BUCKET_NAME, Key=f\u0026#34;{FOLDER_NAME}/{convert_to_s3_key(res[\u0026#39;video\u0026#39;],res[\u0026#39;image\u0026#39;])}\u0026#34;)[\u0026#34;Body\u0026#34;].read() img = Image.open(io.BytesIO(img)) plt.imshow(img) plt.show() 2 Test some queries and visualize the results A drowning prevention drill is taking place. Flooding occurs, and soldiers are deployed to schools to clean up the floodwaters A video clip shows mothers taking care of children with chickenpox. Chickenpox causes blisters to appear all over the children\u0026rsquo;s bodies, accompanied by uncomfortable itching. A video clip of an apple orchard owned by a man. The orchard is vast, filled with many ripe red apples, and visitors happily pick apples, putting them into bags to take home. "
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://vantu-fit.github.io/semantic-video-search/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]